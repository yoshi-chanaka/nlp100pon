{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2s9qnF7tRGDr"
   },
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/News+Aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4E53ug6ofrk"
   },
   "source": [
    "## 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1645687147988,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "g0Dmzheooh8Y",
    "outputId": "590387f3-a91d-486e-e528-5c8e69257225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tFed official says weak data caused by weather, should not slow taper\thttp://www.latimes.com/business/money/la-fi-mo-federal-reserve-plosser-stimulus-economy-20140310,0,1312750.story\\?track=rss\tLos Angeles Times\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.latimes.com\t1394470370698\n",
      "2\tFed's Charles Plosser sees high bar for change in pace of tapering\thttp://www.livemint.com/Politics/H2EvwJSK2VE6OF7iK1g3PP/Feds-Charles-Plosser-sees-high-bar-for-change-in-pace-of-ta.html\tLivemint\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.livemint.com\t1394470371207\n",
      "3\tUS open: Stocks fall after Fed official hints at accelerated tapering\thttp://www.ifamagazine.com/news/us-open-stocks-fall-after-fed-official-hints-at-accelerated-tapering-294436\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371550\n",
      "4\tFed risks falling 'behind the curve', Charles Plosser says\thttp://www.ifamagazine.com/news/fed-risks-falling-behind-the-curve-charles-plosser-says-294430\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371793\n",
      "5\tFed's Plosser: Nasty Weather Has Curbed Job Growth\thttp://www.moneynews.com/Economy/federal-reserve-charles-plosser-weather-job-growth/2014/03/10/id/557011\tMoneynews\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.moneynews.com\t1394470372027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n1\\tFed official says weak data caused by weather, should not slow taper\\thttp://www.latimes.com/business/money/la-fi-mo-federal-reserve-plosser-stimulus-economy-20140310,0,1312750.story\\\\?track=rss\\tLos Angeles Times\\tb\\tddUyU0VZz0BRneMioxUPQVP6sIxvM\\twww.latimes.com\\t1394470370698\\n2\\tFed's Charles Plosser sees high bar for change in pace of tapering\\thttp://www.livemint.com/Politics/H2EvwJSK2VE6OF7iK1g3PP/Feds-Charles-Plosser-sees-high-bar-for-change-in-pace-of-ta.html\\tLivemint\\tb\\tddUyU0VZz0BRneMioxUPQVP6sIxvM\\twww.livemint.com\\t1394470371207\\n3\\tUS open: Stocks fall after Fed official hints at accelerated tapering\\thttp://www.ifamagazine.com/news/us-open-stocks-fall-after-fed-official-hints-at-accelerated-tapering-294436\\tIFA Magazine\\tb\\tddUyU0VZz0BRneMioxUPQVP6sIxvM\\twww.ifamagazine.com\\t1394470371550\\n4\\tFed risks falling 'behind the curve', Charles Plosser says\\thttp://www.ifamagazine.com/news/fed-risks-falling-behind-the-curve-charles-plosser-says-294430\\tIFA Magazine\\tb\\tddUyU0VZz0BRneMioxUPQVP6sIxvM\\twww.ifamagazine.com\\t1394470371793\\n5\\tFed's Plosser: Nasty Weather Has Curbed Job Growth\\thttp://www.moneynews.com/Economy/federal-reserve-charles-plosser-weather-job-growth/2014/03/10/id/557011\\tMoneynews\\tb\\tddUyU0VZz0BRneMioxUPQVP6sIxvM\\twww.moneynews.com\\t1394470372027\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.1 説明変数：openの引数に直接書かずにfilenameを一度宣言する\n",
    "path_corpora = '../data/NewsAggregatorDataset/newsCorpora.csv'\n",
    "path_sessions= '../data/NewsAggregatorDataset/2pageSessions.csv'\n",
    "\n",
    "with open(path_corpora, 'r') as f:\n",
    "    for i in range(5):\n",
    "        line = f.readline().strip()\n",
    "        print(line)\n",
    "\"\"\"\n",
    "1\tFed official says weak data caused by weather, should not slow taper\thttp://www.latimes.com/business/money/la-fi-mo-federal-reserve-plosser-stimulus-economy-20140310,0,1312750.story\\?track=rss\tLos Angeles Times\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.latimes.com\t1394470370698\n",
    "2\tFed's Charles Plosser sees high bar for change in pace of tapering\thttp://www.livemint.com/Politics/H2EvwJSK2VE6OF7iK1g3PP/Feds-Charles-Plosser-sees-high-bar-for-change-in-pace-of-ta.html\tLivemint\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.livemint.com\t1394470371207\n",
    "3\tUS open: Stocks fall after Fed official hints at accelerated tapering\thttp://www.ifamagazine.com/news/us-open-stocks-fall-after-fed-official-hints-at-accelerated-tapering-294436\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371550\n",
    "4\tFed risks falling 'behind the curve', Charles Plosser says\thttp://www.ifamagazine.com/news/fed-risks-falling-behind-the-curve-charles-plosser-says-294430\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371793\n",
    "5\tFed's Plosser: Nasty Weather Has Curbed Job Growth\thttp://www.moneynews.com/Economy/federal-reserve-charles-plosser-weather-job-growth/2014/03/10/id/557011\tMoneynews\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.moneynews.com\t1394470372027\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\n",
      "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ecommerce/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\n",
      "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/2014/ http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n",
      "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/news http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n",
      "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/News-Listing.aspx?Sector=Investing http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndxyGGb4iN9Cs9aMZTKQpJeoiQfruM\\ttechcrunch.com\\tb\\thttp://techcrunch.com/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\\ndxyGGb4iN9Cs9aMZTKQpJeoiQfruM\\ttechcrunch.com\\tb\\thttp://techcrunch.com/ecommerce/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\\ndxyGGb4iN9Cs9aMZTKQpJeoiQfruM\\twww.bnn.ca\\tb\\thttp://www.bnn.ca/News/2014/ http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\\ndxyGGb4iN9Cs9aMZTKQpJeoiQfruM\\twww.bnn.ca\\tb\\thttp://www.bnn.ca/news http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\\ndxyGGb4iN9Cs9aMZTKQpJeoiQfruM\\twww.bnn.ca\\tb\\thttp://www.bnn.ca/News/News-Listing.aspx?Sector=Investing http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(path_sessions, 'r') as f:\n",
    "    for i in range(5):\n",
    "        line = f.readline().strip()\n",
    "        print(line)\n",
    "\"\"\"\n",
    "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\n",
    "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ecommerce/ http://techcrunch.com/2014/03/10/ebay-asks-shareholders-to-vote-against-paypal-split-while-icahn-claims-ceo-incompetence-cost-4b/\n",
    "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/2014/ http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n",
    "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/news http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n",
    "dxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/News-Listing.aspx?Sector=Investing http://www.bnn.ca/News/2014/3/10/EBay-asks-shareholders-to-vote-against-Icahn-board-nominees.aspx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "executionInfo": {
     "elapsed": 3792,
     "status": "ok",
     "timestamp": 1645687151777,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "SNNtxPODoh_c",
    "outputId": "effaaf43-f89a-41e4-ec13-65135ea4b13b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>category</th>\n",
       "      <th>story_id</th>\n",
       "      <th>hostname_url</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  category                       story_id         hostname_url      timestamp  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>hostname_url</th>\n",
       "      <th>category</th>\n",
       "      <th>space_delimited_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dxyGGb4iN9Cs9aMZTKQpJeoiQfruM</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>b</td>\n",
       "      <td>http://techcrunch.com/ http://techcrunch.com/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dxyGGb4iN9Cs9aMZTKQpJeoiQfruM</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>b</td>\n",
       "      <td>http://techcrunch.com/ecommerce/ http://techcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dxyGGb4iN9Cs9aMZTKQpJeoiQfruM</td>\n",
       "      <td>www.bnn.ca</td>\n",
       "      <td>b</td>\n",
       "      <td>http://www.bnn.ca/News/2014/ http://www.bnn.ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dxyGGb4iN9Cs9aMZTKQpJeoiQfruM</td>\n",
       "      <td>www.bnn.ca</td>\n",
       "      <td>b</td>\n",
       "      <td>http://www.bnn.ca/news http://www.bnn.ca/News/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dxyGGb4iN9Cs9aMZTKQpJeoiQfruM</td>\n",
       "      <td>www.bnn.ca</td>\n",
       "      <td>b</td>\n",
       "      <td>http://www.bnn.ca/News/News-Listing.aspx?Secto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        story_id    hostname_url category  \\\n",
       "0  dxyGGb4iN9Cs9aMZTKQpJeoiQfruM  techcrunch.com        b   \n",
       "1  dxyGGb4iN9Cs9aMZTKQpJeoiQfruM  techcrunch.com        b   \n",
       "2  dxyGGb4iN9Cs9aMZTKQpJeoiQfruM      www.bnn.ca        b   \n",
       "3  dxyGGb4iN9Cs9aMZTKQpJeoiQfruM      www.bnn.ca        b   \n",
       "4  dxyGGb4iN9Cs9aMZTKQpJeoiQfruM      www.bnn.ca        b   \n",
       "\n",
       "                                 space_delimited_url  \n",
       "0  http://techcrunch.com/ http://techcrunch.com/2...  \n",
       "1  http://techcrunch.com/ecommerce/ http://techcr...  \n",
       "2  http://www.bnn.ca/News/2014/ http://www.bnn.ca...  \n",
       "3  http://www.bnn.ca/news http://www.bnn.ca/News/...  \n",
       "4  http://www.bnn.ca/News/News-Listing.aspx?Secto...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422419, 8) (15516, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 4.2 一貫性のある簡潔な改行位置\n",
    "\n",
    "df_corpora = pd.read_csv(path_corpora, sep='\\t', header=None,\n",
    "                            names=('id', 'title', 'url', 'publisher', 'category',\n",
    "                                   'story_id', 'hostname_url', 'timestamp'))\n",
    "display(df_corpora.head())\n",
    "\n",
    "df_sessions = pd.read_csv(path_sessions, sep='\\t', header=None,\n",
    "                            names=('story_id', 'hostname_url', 'category', 'space_delimited_url'))\n",
    "display(df_sessions.head())\n",
    "\n",
    "print(df_corpora.shape, df_sessions.shape)\n",
    "\"\"\"\n",
    "\n",
    "id\ttitle\turl\tpublisher\tcategory\tstory_id\thostname_url\ttimestamp\n",
    "0\t1\tFed official says weak data caused by weather,...\thttp://www.latimes.com/business/money/la-fi-mo...\tLos Angeles Times\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.latimes.com\t1394470370698\n",
    "1\t2\tFed's Charles Plosser sees high bar for change...\thttp://www.livemint.com/Politics/H2EvwJSK2VE6O...\tLivemint\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.livemint.com\t1394470371207\n",
    "2\t3\tUS open: Stocks fall after Fed official hints ...\thttp://www.ifamagazine.com/news/us-open-stocks...\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371550\n",
    "3\t4\tFed risks falling 'behind the curve', Charles ...\thttp://www.ifamagazine.com/news/fed-risks-fall...\tIFA Magazine\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.ifamagazine.com\t1394470371793\n",
    "4\t5\tFed's Plosser: Nasty Weather Has Curbed Job Gr...\thttp://www.moneynews.com/Economy/federal-reser...\tMoneynews\tb\tddUyU0VZz0BRneMioxUPQVP6sIxvM\twww.moneynews.com\t1394470372027\n",
    "story_id\thostname_url\tcategory\tspace_delimited_url\n",
    "0\tdxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ http://techcrunch.com/2...\n",
    "1\tdxyGGb4iN9Cs9aMZTKQpJeoiQfruM\ttechcrunch.com\tb\thttp://techcrunch.com/ecommerce/ http://techcr...\n",
    "2\tdxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/2014/ http://www.bnn.ca...\n",
    "3\tdxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/news http://www.bnn.ca/News/...\n",
    "4\tdxyGGb4iN9Cs9aMZTKQpJeoiQfruM\twww.bnn.ca\tb\thttp://www.bnn.ca/News/News-Listing.aspx?Secto...\n",
    "(422419, 8) (15516, 4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1645687152199,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "Gz2XZeNjSWny",
    "outputId": "6f647a9b-45f5-4f35-bd60-1b35a5775b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13340, 8)\n"
     ]
    }
   ],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "df = df_corpora[(df_corpora['publisher'] == 'Reuters') |\n",
    "                (df_corpora['publisher'] == 'Huffington Post') |\n",
    "                (df_corpora['publisher'] == 'Businessweek') |\n",
    "                (df_corpora['publisher'] == 'Contactmusic.com') |\n",
    "                (df_corpora['publisher'] == 'Daily Mail')]\n",
    "print(df.shape) # (13340, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645687152200,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "pAWz-JgtZfme",
    "outputId": "9ef25500-bd31-4b8c-b095-8acd049f4d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10672, 8) (1334, 8) (1334, 8)\n"
     ]
    }
   ],
   "source": [
    "# train, valid, testデータへの分割\n",
    "data_numpy = df.to_numpy()\n",
    "DATASIZE = data_numpy.shape[0]\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(data_numpy)\n",
    "\n",
    "TRAIN_SIZE, VALID_SIZE = \\\n",
    "    int(0.8 * DATASIZE), int(0.1 * DATASIZE)\n",
    "\n",
    "train_data  = data_numpy[: TRAIN_SIZE]\n",
    "valid_data  = data_numpy[TRAIN_SIZE: TRAIN_SIZE + VALID_SIZE]\n",
    "test_data   = data_numpy[TRAIN_SIZE + VALID_SIZE:]\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)\n",
    "# (10672, 8) (1334, 8) (1334, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "# 4.5 一貫性と意味のある並び\n",
    "# データの書き込み\n",
    "article_titles      = {\n",
    "                        'train' : train_data[:, 1].tolist(),\n",
    "                        'valid' : valid_data[:, 1].tolist(),\n",
    "                        'test'  : test_data[:, 1].tolist()\n",
    "                    }\n",
    "article_categories  = {\n",
    "                        'train' : train_data[:, 4].tolist(),\n",
    "                        'valid' : valid_data[:, 4].tolist(),\n",
    "                        'test'  : test_data[:, 4].tolist()\n",
    "                    }\n",
    "\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    f = open('../data/NewsAggregatorDataset/' + kind_of_data + '.txt', 'w', encoding='utf-8')\n",
    "    for categ, title in zip(article_categories[kind_of_data], article_titles[kind_of_data]):\n",
    "        f.write(categ + '\\t' + title + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\tRPT-Fitch Updates EMEA Consumer ABS Rating Criteria & Auto Residual Value  ...\n",
      "e\tGurlitt Wants to Return Nazi-Looted Art, Sueddeutsche Reports\n",
      "b\tUPDATE 1-Fairfax Financial, CEO probed over possible insider trading\n",
      "e\tAngelina Jolie - Angelina Jolie Will Not Tighten Security After Brad Pitt Prank\n",
      "b\tPatent Officials Cancel the Washington Redskins' 'Disparaging' Trademarks\n"
     ]
    }
   ],
   "source": [
    "with open('../data/NewsAggregatorDataset/train.txt', 'r') as f:\n",
    "    for i in range(5):\n",
    "        line = f.readline().strip()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9wHCMV_BJyV"
   },
   "source": [
    "## 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PsX37n2O7aZ"
   },
   "source": [
    "### 方針\n",
    "---  \n",
    "\n",
    "*   titleのベクトル化(TFIDF)\n",
    "*   publisherと hostname_urlをone-hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 出現回数が1のもの\n",
    "* stopwords\n",
    "* 1文字の単語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmZFkiUNiHK_"
   },
   "source": [
    "### titleの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文字数のカウント：出現回数が1のものを削除したい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【保存版】正規表現でエスケープが必要な文字一覧表\n",
    "https://qiita.com/katsukii/items/1c1550f064b4686c04d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpt fitch updates emea consumer abs rating criteria auto residual value gurlitt wants to return nazi looted art sueddeutsche reports update 1 fairfax financial ceo probed over possible insider trading angelina jolie angelina jolie will not tighten security after brad pitt prank patent officials cancel the washington redskins disparaging trademarks the end is nigh monty python reunite for final round of gigs at the o 2 peaches geldof peaches geldof s funeral planned for easter monday corrected wells fargo profit rises 1 4 pct as costs fall us bonds gain for 5 th month amid ecb stimulus bets us stocks rise with dollar treasuries slide on prices update 1 transformers crushes tammy evil to lead weekend box office corrected alibaba shoprunner plan to launch joint china service johnny depp johnny depp hopeless with technology argentina debt dilemma spotlights knotted world of default swaps april fools day a guide to the best and worst pranks on the internet this year us stocks dow hits recor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'[,\\.\\:\\;\\!\\?\\-“”@&\\(\\)\\[\\]\\{\\}\\'\\\"\\t\\/…\\*—\\+\\|_]'\n",
    "train_titles = ' '.join(train_data[:, 1]).lower()\n",
    "train_titles = re.sub(pattern, ' ', train_titles)\n",
    "for n in range(10):\n",
    "    train_titles = f' {str(n)} '.join(train_titles.split(str(n)))\n",
    "train_titles = re.sub(r'\\s\\s+', ' ', train_titles).strip()\n",
    "print(train_titles[:1000])\n",
    "\"\"\"\n",
    "rpt fitch updates emea consumer abs rating criteria auto residual value \n",
    "gurlitt wants to return nazi looted art sueddeutsche reports update 1 fairfax \n",
    "financial ceo probed over possible insider trading angelina jolie angelina jolie \n",
    "will not tighten security after brad pitt prank patent officials cancel the \n",
    "washington redskins disparaging trademarks the end is nigh monty python reunite \n",
    "for final round of gigs at the o 2 peaches geldof peaches geldof s funeral \n",
    "planned for easter monday corrected wells fargo profit rises 1 4 pct as \n",
    "costs fall us bonds gain for 5 th month amid ecb stimulus bets us stocks rise \n",
    "with dollar treasuries slide on prices update 1 transformers crushes tammy evil \n",
    "to lead weekend box office corrected alibaba shoprunner plan to launch joint china \n",
    "service johnny depp johnny depp hopeless with technology argentina debt dilemma \n",
    "spotlights knotted world of default swaps april fools day a guide to the best \n",
    "and worst pranks on the internet this year us stocks dow hits recor\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rpt</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fitch</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>updates</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>consumer</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0       rpt     88\n",
       "1     fitch     73\n",
       "2   updates      7\n",
       "3      emea      1\n",
       "4  consumer     33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n12570\\nword\\tcount\\n0\\trpt\\t88\\n1\\tfitch\\t73\\n2\\tupdates\\t7\\n3\\temea\\t1\\n4\\tconsumer\\t33\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "word_count = collections.Counter(train_titles.split())\n",
    "df_word_count = pd.DataFrame({'word': word_count.keys(),\n",
    "                            'count': word_count.values()})\n",
    "print(len(df_word_count))\n",
    "display(df_word_count.head())\n",
    "\"\"\"\n",
    "12570\n",
    "word\tcount\n",
    "0\trpt\t88\n",
    "1\tfitch\t73\n",
    "2\tupdates\t7\n",
    "3\temea\t1\n",
    "4\tconsumer\t33\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 2870), ('s', 2041), ('in', 1861), ('1', 1647), ('the', 1610), ('of', 1467), ('for', 1358), ('on', 1344), ('2', 1240), ('0', 1190), ('as', 1129), ('update', 1062), ('us', 1054), ('and', 973), ('a', 863), ('with', 758), ('at', 734), ('is', 621), ('3', 603), ('after', 590)]\n"
     ]
    }
   ],
   "source": [
    "print(word_count.most_common(20))\n",
    "\"\"\"\n",
    "[('to', 2870), ('s', 2041), ('in', 1861), ('1', 1647), ('the', 1610), \n",
    "('of', 1467), ('for', 1358), ('on', 1344), ('2', 1240), ('0', 1190), \n",
    "('as', 1129), ('update', 1062), ('us', 1054), ('and', 973), ('a', 863), \n",
    "('with', 758), ('at', 734), ('is', 621), ('3', 603), ('after', 590)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "5020\n",
      "['emea', 'criteria', 'residual', 'nazi', 'looted', 'sueddeutsche', 'tighten', 'disparaging', 'nigh', 'shoprunner', 'hopeless', 'spotlights', 'knotted', 'pranks', 'matex', 'melbourne', 'rayban', 't$', 'chatshow', 'reverts', 'lebowitz', 'everbright', 'raknet', 'greeted', 'boos', 'flame', 'retardant', 'chevy', 'ivf', 'techniques', 'unsafe', 'hesitate', 'considered', 'nationalizing', 'mekhi', 'phifer', 'classed', 'midlife', 'prompted', 'evolves', 'meteoroids', 'bombard', 'scooter', 'scheming', 'archaic', 'transcanada', 'kitimat', 'welcoming', 'blew', 'truly', 'gwynnie', 'thankfully', 'laboeuf', 'filmmaker', 'windshield', 'washer', 'fluid', 'sprays', 'germs', 'legionnaires', 'screamed', 'peta', 'murgatroyd', 'brooke', 'extraordinarily', 'criticizes', 'cancellation', 'brill', 'timelines', 'ages', 'genie', 'vivid', 'avengersâ€™', 'fingers', 'dazeem', 'showbiz', 'arabic', 'hypertension', 'fasting', 'diets', 'reducing', '#containcolbert', 'executes', 'whitmore', 'millie', 'mackintosh', 'slew', 'gowns', 'catwoman', 'transpacific', 'unintentionally', 'wilmerhale', 'litigator', 'montage', 'pentagon', 'writebol', 'stricken', 'missionary', 'credibility', 'cronenbergâ€™s']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# https://nashidos.hatenablog.com/entry/2020/08/12/205119\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "for word in ['up', 'down', 'over', 'under']:\n",
    "    stop_words.remove(word)\n",
    "print(len(stop_words))\n",
    "print(stop_words, end = '\\n\\n')\n",
    "\n",
    "low_freq_words = df_word_count[df_word_count['count'] == 1]['word'].to_numpy().tolist()\n",
    "print(len(low_freq_words))\n",
    "print(low_freq_words[:100])\n",
    "\n",
    "# 175\n",
    "# ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# 5020\n",
    "# ['emea', 'criteria', 'residual', 'nazi', 'looted', 'sueddeutsche', 'tighten', 'disparaging', 'nigh', 'shoprunner', 'hopeless', 'spotlights', 'knotted', 'pranks', 'matex', 'melbourne', 'rayban', 't$', 'chatshow', 'reverts', 'lebowitz', 'everbright', 'raknet', 'greeted', 'boos', 'flame', 'retardant', 'chevy', 'ivf', 'techniques', 'unsafe', 'hesitate', 'considered', 'nationalizing', 'mekhi', 'phifer', 'classed', 'midlife', 'prompted', 'evolves', 'meteoroids', 'bombard', 'scooter', 'scheming', 'archaic', 'transcanada', 'kitimat', 'welcoming', 'blew', 'truly', 'gwynnie', 'thankfully', 'laboeuf', 'filmmaker', 'windshield', 'washer', 'fluid', 'sprays', 'germs', 'legionnaires', 'screamed', 'peta', 'murgatroyd', 'brooke', 'extraordinarily', 'criticizes', 'cancellation', 'brill', 'timelines', 'ages', 'genie', 'vivid', 'avengersâ€™', 'fingers', 'dazeem', 'showbiz', 'arabic', 'hypertension', 'fasting', 'diets', 'reducing', '#containcolbert', 'executes', 'whitmore', 'millie', 'mackintosh', 'slew', 'gowns', 'catwoman', 'transpacific', 'unintentionally', 'wilmerhale', 'litigator', 'montage', 'pentagon', 'writebol', 'stricken', 'missionary', 'credibility', 'cronenbergâ€™s']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 6.6 コードの意図を書く：入力テキストに対して複数の処理をしているのでコメントをつける\n",
    "def PreprocessingText(input_text, kind=None):\n",
    "\n",
    "    global stop_words, low_freq_words\n",
    "\n",
    "    processed_text = input_text.lower()\n",
    "\n",
    "    # 記号の削除\n",
    "    pattern = r'[,\\.\\:\\;\\!\\?\\-“”@&\\(\\)\\[\\]\\{\\}\\'\\\"\\t\\/…\\*—\\+\\|_]'\n",
    "    processed_text = re.sub(pattern, ' ', processed_text)\n",
    "\n",
    "    # 数字の分離\n",
    "    for n in range(10):\n",
    "        processed_text = f' {str(n)} '.join(processed_text.split(str(n)))\n",
    "\n",
    "    # アルファベット1文字の削除\n",
    "    processed_text = re.sub(r'\\s[a-z]\\s', ' ', processed_text)\n",
    "\n",
    "    # 2つ以上のスペースの連続を1つのスペースに\n",
    "    processed_text = re.sub(r'\\s\\s+', ' ', processed_text)\n",
    "\n",
    "    # stop_words等の削除\n",
    "    remove_words = set(stop_words)\n",
    "    words_in_text = processed_text.strip().split()\n",
    "    processed_text = ' '.join([w for w in words_in_text if w not in remove_words])\n",
    "    processed_text_add_lowfreq = processed_text\n",
    "\n",
    "    # low_freq_words等の削除\n",
    "    remove_words = set(low_freq_words)\n",
    "    words_in_text = processed_text.strip().split()\n",
    "    processed_text = ' '.join([w for w in words_in_text if w not in remove_words])\n",
    "\n",
    "    # 低頻度の単語を除いた結果単語数が0になってしまったものは，printして一つ前の段階のものを返す\n",
    "    if len(processed_text) == 0:\n",
    "        print(kind + ': ', input_text,\n",
    "            '=> ', processed_text_add_lowfreq)\n",
    "        return processed_text_add_lowfreq\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurlitt Wants to Return Nazi-Looted Art, Sueddeutsche Reports\n",
      "gurlitt wants return art reports\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGurlitt Wants to Return Nazi-Looted Art, Sueddeutsche Reports\\ngurlitt wants return art reports\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "print(train_data[:, 1][idx])\n",
    "print(PreprocessingText(train_data[:, 1][idx]))\n",
    "\"\"\"\n",
    "Gurlitt Wants to Return Nazi-Looted Art, Sueddeutsche Reports\n",
    "gurlitt wants return art reports\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rR5Lmf5hSePI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  A Timeless Gift =>  timeless gift\n",
      "train:  Goop, She Did It Again =>  goop\n"
     ]
    }
   ],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "titles_train    = [PreprocessingText(t, 'train')    for t in train_data[:, 1].copy()]\n",
    "titles_valid    = [PreprocessingText(t, 'valid')    for t in valid_data[:, 1].copy()]\n",
    "titles_test     = [PreprocessingText(t, 'test')     for t in test_data[:, 1].copy()]\n",
    "# train:  A Timeless Gift =>  timeless gift\n",
    "# train:  Goop, She Did It Again =>  goop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1645687196508,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "oLdnP94qG9Wf",
    "outputId": "2d6d129b-1b3e-4d47-d0aa-340670f81ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7384\n",
      "<class 'numpy.ndarray'> (10672, 7384) (1334, 7384) (1334, 7384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_train = vectorizer.fit_transform(titles_train).toarray()\n",
    "vocab = list(vectorizer.get_feature_names())\n",
    "print(len(vocab))\n",
    "\n",
    "tfidf_valid = vectorizer.transform(titles_valid).toarray()\n",
    "tfidf_test= vectorizer.transform(titles_test).toarray()\n",
    "print(type(tfidf_train), tfidf_train.shape, tfidf_valid.shape, tfidf_test.shape)\n",
    "\n",
    "# 7384\n",
    "# <class 'numpy.ndarray'> (10672, 7384) (1334, 7384) (1334, 7384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-ABEb7ISeaA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNNwaEW_iNhY"
   },
   "source": [
    "### publisher, hostname, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1645687197465,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "rZoqEwhbZ5Bz",
    "outputId": "50c5c85a-aea0-4fe1-ebfb-03c10894f930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Contactmusic.com', 'Daily Mail', 'Reuters', 'Huffington Post', 'Businessweek'}\n",
      "{'www.contactmusic.com', 'in.reuters.com', 'www.businessweek.com', 'www.huffingtonpost.com', 'www.dailymail.co.uk', 'www.reuters.com'}\n",
      "{'m', 'b', 't', 'e'}\n"
     ]
    }
   ],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "# 4.5 一貫性と意味のある並び\n",
    "publishers      = set(train_data[:, 3].tolist())\n",
    "hostname_url    = set(train_data[:, 6].tolist())\n",
    "categories      = set(train_data[:, 4].tolist())\n",
    "\n",
    "print(publishers)\n",
    "print(hostname_url)\n",
    "print(categories)\n",
    "\n",
    "# {'Contactmusic.com', 'Daily Mail', 'Reuters', 'Huffington Post', 'Businessweek'}\n",
    "# {'www.contactmusic.com', 'in.reuters.com', 'www.businessweek.com', 'www.huffingtonpost.com', 'www.dailymail.co.uk', 'www.reuters.com'}\n",
    "# {'m', 'b', 't', 'e'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>b</th>\n",
       "      <th>t</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Contactmusic.com</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily Mail</th>\n",
       "      <td>208.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>136.0</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>258.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Businessweek</th>\n",
       "      <td>107.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      m       b      t       e\n",
       "Contactmusic.com    8.0     1.0   11.0  1845.0\n",
       "Daily Mail        208.0   170.0  250.0  1185.0\n",
       "Reuters           136.0  2515.0  302.0   145.0\n",
       "Huffington Post   258.0   349.0  373.0   988.0\n",
       "Businessweek      107.0  1458.0  294.0    69.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\tm\\tb\\tt\\te\\nContactmusic.com\\t8.0\\t1.0\\t11.0\\t1845.0\\nDaily Mail\\t208.0\\t170.0\\t250.0\\t1185.0\\nReuters\\t136.0\\t2515.0\\t302.0\\t145.0\\nHuffington Post\\t258.0\\t349.0\\t373.0\\t988.0\\nBusinessweek\\t107.0\\t1458.0\\t294.0\\t69.0\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_cat_counter = pd.DataFrame(np.zeros((len(publishers), len(categories))),\n",
    "                                index=publishers, columns=categories)\n",
    "for category, publisher in train_data[:, [4, 3]]:\n",
    "    pub_cat_counter[category][publisher] += 1\n",
    "display(pub_cat_counter)\n",
    "\"\"\"\n",
    "\tm\tb\tt\te\n",
    "Contactmusic.com\t8.0\t1.0\t11.0\t1845.0\n",
    "Daily Mail\t208.0\t170.0\t250.0\t1185.0\n",
    "Reuters\t136.0\t2515.0\t302.0\t145.0\n",
    "Huffington Post\t258.0\t349.0\t373.0\t988.0\n",
    "Businessweek\t107.0\t1458.0\t294.0\t69.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLP3kqF9ZW5q"
   },
   "source": [
    "* 各々のpublishersで記事のcategoryに偏りがあるので，publishersは良い特徴量になりそう\n",
    "* hostnameに関しても同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>b</th>\n",
       "      <th>t</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>www.contactmusic.com</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in.reuters.com</th>\n",
       "      <td>92.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.businessweek.com</th>\n",
       "      <td>107.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.huffingtonpost.com</th>\n",
       "      <td>258.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.dailymail.co.uk</th>\n",
       "      <td>208.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.reuters.com</th>\n",
       "      <td>44.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            m       b      t       e\n",
       "www.contactmusic.com      8.0     1.0   11.0  1845.0\n",
       "in.reuters.com           92.0  1664.0  179.0    94.0\n",
       "www.businessweek.com    107.0  1458.0  294.0    69.0\n",
       "www.huffingtonpost.com  258.0   349.0  373.0   988.0\n",
       "www.dailymail.co.uk     208.0   170.0  250.0  1185.0\n",
       "www.reuters.com          44.0   851.0  123.0    51.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "host_cat_counter = pd.DataFrame(np.zeros((len(hostname_url), len(categories))),\n",
    "                                index=hostname_url, columns=categories)\n",
    "for category, host in train_data[:, [4, 6]]:\n",
    "    host_cat_counter[category][host] += 1\n",
    "display(host_cat_counter)\n",
    "\"\"\"\n",
    "\tm\tb\tt\te\n",
    "www.contactmusic.com\t8.0\t1.0\t11.0\t1845.0\n",
    "in.reuters.com\t92.0\t1664.0\t179.0\t94.0\n",
    "www.businessweek.com\t107.0\t1458.0\t294.0\t69.0\n",
    "www.huffingtonpost.com\t258.0\t349.0\t373.0\t988.0\n",
    "www.dailymail.co.uk\t208.0\t170.0\t250.0\t1185.0\n",
    "www.reuters.com\t44.0\t851.0\t123.0\t51.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o7s4L9zqT_No"
   },
   "outputs": [],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "# 4.5 一貫性と意味のある並び：train, valid, testの順で処理\n",
    "df_train    = pd.DataFrame({'word_{}'.format(w): col for w, col in zip(vocab, tfidf_train.T)})\n",
    "df_valid    = pd.DataFrame({'word_{}'.format(w): col for w, col in zip(vocab, tfidf_valid.T)})\n",
    "df_test     = pd.DataFrame({'word_{}'.format(w): col for w, col in zip(vocab, tfidf_test.T)})\n",
    "\n",
    "df_train['publisher']   = train_data[:, 3]\n",
    "df_valid['publisher']   = valid_data[:, 3]\n",
    "df_test['publisher']    = test_data[:, 3]\n",
    "\n",
    "df_train['hostname_url']    = train_data[:, 6]\n",
    "df_valid['hostname_url']    = valid_data[:, 6]\n",
    "df_test['hostname_url']     = test_data[:, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsV1P76Bgj-J"
   },
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1645687219393,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "uGTf0maUK8qb",
    "outputId": "b1e9e2e6-4275-4112-abdf-20d62f8f6225"
   },
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([df_train, df_valid, df_test], axis=0)\n",
    "df_concatenated = pd.get_dummies(df_concatenated, columns=['publisher', 'hostname_url'])\n",
    "\n",
    "train_end_idx, valid_end_idx = df_train.shape[0], df_train.shape[0] + df_valid.shape[0]\n",
    "# 4.4 縦の線をまっすぐにする\n",
    "df_train    = df_concatenated[              : train_end_idx ].reset_index(drop=True)\n",
    "df_valid    = df_concatenated[train_end_idx : valid_end_idx ].reset_index(drop=True)\n",
    "df_test     = df_concatenated[valid_end_idx :               ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10672, 7396) (1334, 7396) (1334, 7396)\n"
     ]
    }
   ],
   "source": [
    "category_dic = {'b': 0, 't': 1, 'e': 2, 'm': 3}\n",
    "df_train['category']    = [category_dic[c] for c in train_data[:, 4]]\n",
    "df_valid['category']    = [category_dic[c] for c in valid_data[:, 4]]\n",
    "df_test['category']     = [category_dic[c] for c in test_data[:, 4]]\n",
    "print(df_train.shape, df_valid.shape, df_test.shape)\n",
    "# (10672, 7396) (1334, 7396) (1334, 7396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {'train': df_train.to_numpy(), \n",
    "                'valid': df_valid.to_numpy(), \n",
    "                'test': df_test.to_numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5dQtBlzg9xx"
   },
   "source": [
    "### 特徴量の保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.feature.txt，valid.feature.txt，test.feature.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3taV81jChRHn"
   },
   "outputs": [],
   "source": [
    "columns = list(df_train.columns)\n",
    "\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    path = '../data/NewsAggregatorDataset/'\n",
    "    f = open(path + kind_of_data + '.feature.txt', 'w', encoding='utf-8')\n",
    "    f.write('\\t'.join(columns) + '\\n')\n",
    "    for features_line in features_dict[kind_of_data]:\n",
    "        f.write('\\t'.join(features_line.astype(str).tolist()) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-fSw1G_hRKS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpjCisovflc6"
   },
   "source": [
    "## 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (10672, 7395), 10672\n",
      "valid: (1334, 7395), 1334\n",
      "test: (1334, 7395), 1334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrain: (10672, 7395), 10672\\nvalid: (1334, 7395), 1334\\ntest: (1334, 7395), 1334\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *.feature.txtからのデータの読み込み\n",
    "import pandas as pd\n",
    "\n",
    "X, y = {}, {}\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    path = '../data/NewsAggregatorDataset/'\n",
    "    df = pd.read_table(path + kind_of_data + '.feature.txt')\n",
    "    X[kind_of_data] = df.drop('category', axis=1).values\n",
    "    y[kind_of_data] = df['category'].values\n",
    "    print(f'{kind_of_data}: {X[kind_of_data].shape}, {len(y[kind_of_data])}')\n",
    "\"\"\"\n",
    "train: (10672, 7395), 10672\n",
    "valid: (1334, 7395), 1334\n",
    "test: (1334, 7395), 1334\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53892,
     "status": "ok",
     "timestamp": 1645687449566,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "UOQcGgXof7O6",
    "outputId": "a5cea634-777d-4c16-e223-2b4b56ca60a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X['train'], y['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTDFNbBKIEdc"
   },
   "source": [
    "## 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "[[0.9377 0.0295 0.0202 0.0127]\n",
      " [0.5289 0.1453 0.257  0.0687]\n",
      " [0.9434 0.0355 0.0097 0.0114]\n",
      " ...\n",
      " [0.0776 0.1058 0.7403 0.0763]\n",
      " [0.0005 0.0018 0.9965 0.0012]\n",
      " [0.0011 0.0029 0.9928 0.0032]]\n",
      "\n",
      "valid:\n",
      "[[0.9338 0.0246 0.0198 0.0219]\n",
      " [0.1247 0.0892 0.7404 0.0456]\n",
      " [0.0005 0.0027 0.9942 0.0025]\n",
      " ...\n",
      " [0.5221 0.0503 0.0231 0.4045]\n",
      " [0.1997 0.1131 0.6109 0.0762]\n",
      " [0.0001 0.0004 0.9991 0.0004]]\n",
      "\n",
      "test:\n",
      "[[0.8958 0.0699 0.0192 0.0151]\n",
      " [0.0017 0.0065 0.9868 0.0049]\n",
      " [0.1112 0.2023 0.522  0.1645]\n",
      " ...\n",
      " [0.9201 0.0303 0.031  0.0186]\n",
      " [0.614  0.1599 0.0934 0.1327]\n",
      " [0.0145 0.0299 0.9417 0.0138]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    y_pred_proba = clf.predict_proba(X[kind_of_data])\n",
    "    print('{}:\\n{}'.format(kind_of_data, y_pred_proba), end='\\n\\n')\n",
    "\"\"\"\n",
    "train:\n",
    "[[0.9377 0.0295 0.0202 0.0127]\n",
    " [0.5289 0.1453 0.257  0.0687]\n",
    " [0.9434 0.0355 0.0097 0.0114]\n",
    " ...\n",
    " [0.0776 0.1058 0.7403 0.0763]\n",
    " [0.0005 0.0018 0.9965 0.0012]\n",
    " [0.0011 0.0029 0.9928 0.0032]]\n",
    "\n",
    "valid:\n",
    "[[0.9338 0.0246 0.0198 0.0219]\n",
    " [0.1247 0.0892 0.7404 0.0456]\n",
    " [0.0005 0.0027 0.9942 0.0025]\n",
    " ...\n",
    " [0.5221 0.0503 0.0231 0.4045]\n",
    " [0.1997 0.1131 0.6109 0.0762]\n",
    " [0.0001 0.0004 0.9991 0.0004]]\n",
    "\n",
    "test:\n",
    "[[0.8958 0.0699 0.0192 0.0151]\n",
    " [0.0017 0.0065 0.9868 0.0049]\n",
    " [0.1112 0.2023 0.522  0.1645]\n",
    " ...\n",
    " [0.9201 0.0303 0.031  0.0186]\n",
    " [0.614  0.1599 0.0934 0.1327]\n",
    " [0.0145 0.0299 0.9417 0.0138]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7o2fSoAWII5N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKcZB1Z0IHtV"
   },
   "source": [
    "## 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccuracy(y_true, y_pred):\n",
    "    if (len(y_true) == 0) or (len(y_true) != len(y_pred)):\n",
    "        return False\n",
    "    return np.sum(np.array(y_true) == np.array(y_pred)) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t0.9371251874062968\n",
      "valid:\t0.8853073463268366\n",
      "test:\t0.8800599700149925\n"
     ]
    }
   ],
   "source": [
    "pred_labels = {}\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    y_pred = clf.predict(X[kind_of_data])\n",
    "    # 8.1 説明変数：printする前に計算した正解率を変数accuracyに代入\n",
    "    # 6.7 名前付き引数\n",
    "    accuracy = ComputeAccuracy(\n",
    "                                y_true=y[kind_of_data],\n",
    "                                y_pred=y_pred\n",
    "                            )\n",
    "    print('{}:\\t{}'.format(kind_of_data, accuracy))\n",
    "\n",
    "    # 問55で使うためラベルを記録\n",
    "    pred_labels[kind_of_data] = y_pred\n",
    "\n",
    "# train:\t0.9371251874062968\n",
    "# valid:\t0.8853073463268366\n",
    "# test:\t0.8800599700149925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOW6d-M4FqOF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbdYkc7wF38d"
   },
   "source": [
    "## 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv9fUx58kVw3"
   },
   "source": [
    "混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_b</th>\n",
       "      <th>pred_t</th>\n",
       "      <th>pred_e</th>\n",
       "      <th>pred_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_b</th>\n",
       "      <td>526</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_t</th>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_e</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_m</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_b  pred_t  pred_e  pred_m\n",
       "true_b     526      15      22       1\n",
       "true_t      38      95      22       2\n",
       "true_e      13       1     502       1\n",
       "true_m      22       2      21      51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_b</th>\n",
       "      <th>pred_t</th>\n",
       "      <th>pred_e</th>\n",
       "      <th>pred_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_b</th>\n",
       "      <td>526</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_t</th>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_e</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_m</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_b  pred_t  pred_e  pred_m\n",
       "true_b     526      15      22       1\n",
       "true_t      38      95      22       2\n",
       "true_e      13       1     502       1\n",
       "true_m      22       2      21      51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_b</th>\n",
       "      <th>pred_t</th>\n",
       "      <th>pred_e</th>\n",
       "      <th>pred_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_b</th>\n",
       "      <td>526</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_t</th>\n",
       "      <td>38</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_e</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_m</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_b  pred_t  pred_e  pred_m\n",
       "true_b     526      15      22       1\n",
       "true_t      38      95      22       2\n",
       "true_e      13       1     502       1\n",
       "true_m      22       2      21      51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "\n",
    "    # 6.7 名前付き引数\n",
    "    confusion_mx = confusion_matrix(\n",
    "                                        y_true = y[kind_of_data],\n",
    "                                        y_pred = pred_labels[kind_of_data]\n",
    "                                )\n",
    "    confusion_mx_df = pd.DataFrame(\n",
    "                                    confusion_mx,\n",
    "                                    index=['true_b', 'true_t', 'true_e', 'true_m'],\n",
    "                                    columns=['pred_b', 'pred_t', 'pred_e', 'pred_m']\n",
    "                                )\n",
    "    print(kind_of_data + ':')\n",
    "    display(cf_matrix_df)\n",
    "\"\"\"\n",
    "train:\n",
    "pred_b\tpred_t\tpred_e\tpred_m\n",
    "true_b\t526\t15\t22\t1\n",
    "true_t\t38\t95\t22\t2\n",
    "true_e\t13\t1\t502\t1\n",
    "true_m\t22\t2\t21\t51\n",
    "valid:\n",
    "pred_b\tpred_t\tpred_e\tpred_m\n",
    "true_b\t526\t15\t22\t1\n",
    "true_t\t38\t95\t22\t2\n",
    "true_e\t13\t1\t502\t1\n",
    "true_m\t22\t2\t21\t51\n",
    "test:\n",
    "pred_b\tpred_t\tpred_e\tpred_m\n",
    "true_b\t526\t15\t22\t1\n",
    "true_t\t38\t95\t22\t2\n",
    "true_e\t13\t1\t502\t1\n",
    "true_m\t22\t2\t21\t51\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HB68f8LQRHcg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13uUMPy9H6zy"
   },
   "source": [
    "## 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>適合率</th>\n",
       "      <th>再現率</th>\n",
       "      <th>F1スコア</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.926891</td>\n",
       "      <td>0.973514</td>\n",
       "      <td>0.949631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.950446</td>\n",
       "      <td>0.779675</td>\n",
       "      <td>0.856632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.938919</td>\n",
       "      <td>0.977079</td>\n",
       "      <td>0.957619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.987037</td>\n",
       "      <td>0.743375</td>\n",
       "      <td>0.848051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.937125</td>\n",
       "      <td>0.937125</td>\n",
       "      <td>0.937125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.868411</td>\n",
       "      <td>0.902983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            適合率       再現率     F1スコア\n",
       "b      0.926891  0.973514  0.949631\n",
       "t      0.950446  0.779675  0.856632\n",
       "e      0.938919  0.977079  0.957619\n",
       "m      0.987037  0.743375  0.848051\n",
       "micro  0.937125  0.937125  0.937125\n",
       "macro  0.950823  0.868411  0.902983"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>適合率</th>\n",
       "      <th>再現率</th>\n",
       "      <th>F1スコア</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.890344</td>\n",
       "      <td>0.954386</td>\n",
       "      <td>0.921253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.869863</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.912029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.525773</td>\n",
       "      <td>0.684564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.909382</td>\n",
       "      <td>0.751998</td>\n",
       "      <td>0.803569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            適合率       再現率     F1スコア\n",
       "b      0.890344  0.954386  0.921253\n",
       "t      0.896552  0.569343  0.696429\n",
       "e      0.869863  0.958491  0.912029\n",
       "m      0.980769  0.525773  0.684564\n",
       "micro  0.885307  0.885307  0.885307\n",
       "macro  0.909382  0.751998  0.803569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>適合率</th>\n",
       "      <th>再現率</th>\n",
       "      <th>F1スコア</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.878130</td>\n",
       "      <td>0.932624</td>\n",
       "      <td>0.904557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.605096</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.885362</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.926199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.675497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.880060</td>\n",
       "      <td>0.880060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.882868</td>\n",
       "      <td>0.759989</td>\n",
       "      <td>0.802489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            適合率       再現率     F1スコア\n",
       "b      0.878130  0.932624  0.904557\n",
       "t      0.840708  0.605096  0.703704\n",
       "e      0.885362  0.970986  0.926199\n",
       "m      0.927273  0.531250  0.675497\n",
       "micro  0.880060  0.880060  0.880060\n",
       "macro  0.882868  0.759989  0.802489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 4.2 一貫性のある簡潔な改行位置：似ているコードは似ているように見せる\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # 適合率\n",
    "    scores.append(\n",
    "                    precision_score(y[kind_of_data], pred_labels[kind_of_data], average=None).tolist() +\n",
    "                    [precision_score(y[kind_of_data], pred_labels[kind_of_data], average='micro')] +\n",
    "                    [precision_score(y[kind_of_data], pred_labels[kind_of_data], average='macro')]\n",
    "                )\n",
    "\n",
    "    # 再現率\n",
    "    scores.append(\n",
    "                    recall_score(y[kind_of_data], pred_labels[kind_of_data], average=None).tolist() +\n",
    "                    [recall_score(y[kind_of_data], pred_labels[kind_of_data], average='micro')] +\n",
    "                    [recall_score(y[kind_of_data], pred_labels[kind_of_data], average='macro')]\n",
    "                )\n",
    "\n",
    "    # F1スコア\n",
    "    scores.append(\n",
    "                    f1_score(y[kind_of_data], pred_labels[kind_of_data], average=None).tolist() +\n",
    "                    [f1_score(y[kind_of_data], pred_labels[kind_of_data], average='micro')] +\n",
    "                    [f1_score(y[kind_of_data], pred_labels[kind_of_data], average='macro')]\n",
    "                )\n",
    "\n",
    "    print(kind_of_data + ':')\n",
    "    display(pd.DataFrame(np.array(scores).T,\n",
    "                        columns=['適合率', '再現率', 'F1スコア'],\n",
    "                        index = ['b', 't', 'e', 'm', 'micro', 'macro']))\n",
    "\"\"\"\n",
    "train:\n",
    "適合率\t再現率\tF1スコア\n",
    "b\t0.926891\t0.973514\t0.949631\n",
    "t\t0.950446\t0.779675\t0.856632\n",
    "e\t0.938919\t0.977079\t0.957619\n",
    "m\t0.987037\t0.743375\t0.848051\n",
    "micro\t0.937125\t0.937125\t0.937125\n",
    "macro\t0.950823\t0.868411\t0.902983\n",
    "valid:\n",
    "適合率\t再現率\tF1スコア\n",
    "b\t0.890344\t0.954386\t0.921253\n",
    "t\t0.896552\t0.569343\t0.696429\n",
    "e\t0.869863\t0.958491\t0.912029\n",
    "m\t0.980769\t0.525773\t0.684564\n",
    "micro\t0.885307\t0.885307\t0.885307\n",
    "macro\t0.909382\t0.751998\t0.803569\n",
    "test:\n",
    "適合率\t再現率\tF1スコア\n",
    "b\t0.878130\t0.932624\t0.904557\n",
    "t\t0.840708\t0.605096\t0.703704\n",
    "e\t0.885362\t0.970986\t0.926199\n",
    "m\t0.927273\t0.531250\t0.675497\n",
    "micro\t0.880060\t0.880060\t0.880060\n",
    "macro\t0.882868\t0.759989\t0.802489\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8to5shJG8Ag"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Hg1NA_WJZSs"
   },
   "source": [
    "## 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645687451027,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "gp09Gc27WY7_",
    "outputId": "ee01eaeb-044e-4895-d51f-b0d9e4434b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2026 -0.4538 -0.1326 ... -0.2676 -0.0831  0.4514]\n",
      " [-0.125   0.5919 -0.1169 ... -0.0464  0.0082  0.0731]\n",
      " [ 0.0095 -0.0712  0.3539 ...  0.1648  0.0104 -0.3998]\n",
      " [-0.0871 -0.0669 -0.1044 ...  0.1492  0.0646 -0.1247]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_)\n",
    "\"\"\"\n",
    "[[ 0.2026 -0.4538 -0.1326 ... -0.2676 -0.0831  0.4514]\n",
    " [-0.125   0.5919 -0.1169 ... -0.0464  0.0082  0.0731]\n",
    " [ 0.0095 -0.0712  0.3539 ...  0.1648  0.0104 -0.3998]\n",
    " [-0.0871 -0.0669 -0.1044 ...  0.1492  0.0646 -0.1247]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argsort使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\narray([[0, 1, 2, 3],\\n       [2, 0, 3, 1],\\n       [1, 2, 3, 0]], dtype=int64)\\n'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用例\n",
    "tmp_ndarray = np.array([[1, 2, 3, 4],\n",
    "                        [2, 4, 1, 3],\n",
    "                        [4, 1, 2, 3]])\n",
    "np.argsort(tmp_ndarray, axis=1)\n",
    "\"\"\"\n",
    "array([[0, 1, 2, 3],\n",
    "       [2, 0, 3, 1],\n",
    "       [1, 2, 3, 0]], dtype=int64)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b(business)_top</th>\n",
       "      <th>b(business)_bottom</th>\n",
       "      <th>t(science and technology)_top</th>\n",
       "      <th>t(science and technology)_bottom</th>\n",
       "      <th>e(entertainment)_top</th>\n",
       "      <th>e(entertainment)_bottom</th>\n",
       "      <th>m(health)_top</th>\n",
       "      <th>m(health)_bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_bank</td>\n",
       "      <td>word_ebola</td>\n",
       "      <td>word_google</td>\n",
       "      <td>word_stocks</td>\n",
       "      <td>word_kardashian</td>\n",
       "      <td>word_google</td>\n",
       "      <td>word_ebola</td>\n",
       "      <td>word_facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_obamacare</td>\n",
       "      <td>word_aereo</td>\n",
       "      <td>word_facebook</td>\n",
       "      <td>word_fed</td>\n",
       "      <td>word_cannes</td>\n",
       "      <td>word_study</td>\n",
       "      <td>word_study</td>\n",
       "      <td>word_gm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_fed</td>\n",
       "      <td>word_microsoft</td>\n",
       "      <td>word_apple</td>\n",
       "      <td>word_american</td>\n",
       "      <td>word_film</td>\n",
       "      <td>word_facebook</td>\n",
       "      <td>word_fda</td>\n",
       "      <td>word_apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_stocks</td>\n",
       "      <td>word_apple</td>\n",
       "      <td>word_microsoft</td>\n",
       "      <td>word_shares</td>\n",
       "      <td>word_kim</td>\n",
       "      <td>word_could</td>\n",
       "      <td>word_cancer</td>\n",
       "      <td>word_google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_ukraine</td>\n",
       "      <td>word_samsung</td>\n",
       "      <td>word_climate</td>\n",
       "      <td>word_drug</td>\n",
       "      <td>word_star</td>\n",
       "      <td>word_climate</td>\n",
       "      <td>word_mers</td>\n",
       "      <td>word_climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>word_ecb</td>\n",
       "      <td>word_fda</td>\n",
       "      <td>word_tesla</td>\n",
       "      <td>word_ecb</td>\n",
       "      <td>word_thrones</td>\n",
       "      <td>word_us</td>\n",
       "      <td>word_drug</td>\n",
       "      <td>word_twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_china</td>\n",
       "      <td>word_facebook</td>\n",
       "      <td>word_gm</td>\n",
       "      <td>word_cancer</td>\n",
       "      <td>word_miley</td>\n",
       "      <td>word_billion</td>\n",
       "      <td>word_health</td>\n",
       "      <td>word_deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>word_oil</td>\n",
       "      <td>word_google</td>\n",
       "      <td>word_nasa</td>\n",
       "      <td>word_ebola</td>\n",
       "      <td>word_chris</td>\n",
       "      <td>word_obamacare</td>\n",
       "      <td>word_cdc</td>\n",
       "      <td>word_kardashian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>word_euro</td>\n",
       "      <td>word_drug</td>\n",
       "      <td>word_fcc</td>\n",
       "      <td>word_day</td>\n",
       "      <td>word_cyrus</td>\n",
       "      <td>word_apple</td>\n",
       "      <td>word_cases</td>\n",
       "      <td>word_ceo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>word_mcdonald</td>\n",
       "      <td>word_mers</td>\n",
       "      <td>word_earth</td>\n",
       "      <td>word_percent</td>\n",
       "      <td>word_show</td>\n",
       "      <td>word_ceo</td>\n",
       "      <td>word_outbreak</td>\n",
       "      <td>word_bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  b(business)_top b(business)_bottom t(science and technology)_top  \\\n",
       "0       word_bank         word_ebola                   word_google   \n",
       "1  word_obamacare         word_aereo                 word_facebook   \n",
       "2        word_fed     word_microsoft                    word_apple   \n",
       "3     word_stocks         word_apple                word_microsoft   \n",
       "4    word_ukraine       word_samsung                  word_climate   \n",
       "5        word_ecb           word_fda                    word_tesla   \n",
       "6      word_china      word_facebook                       word_gm   \n",
       "7        word_oil        word_google                     word_nasa   \n",
       "8       word_euro          word_drug                      word_fcc   \n",
       "9   word_mcdonald          word_mers                    word_earth   \n",
       "\n",
       "  t(science and technology)_bottom e(entertainment)_top  \\\n",
       "0                      word_stocks      word_kardashian   \n",
       "1                         word_fed          word_cannes   \n",
       "2                    word_american            word_film   \n",
       "3                      word_shares             word_kim   \n",
       "4                        word_drug            word_star   \n",
       "5                         word_ecb         word_thrones   \n",
       "6                      word_cancer           word_miley   \n",
       "7                       word_ebola           word_chris   \n",
       "8                         word_day           word_cyrus   \n",
       "9                     word_percent            word_show   \n",
       "\n",
       "  e(entertainment)_bottom  m(health)_top m(health)_bottom  \n",
       "0             word_google     word_ebola    word_facebook  \n",
       "1              word_study     word_study          word_gm  \n",
       "2           word_facebook       word_fda       word_apple  \n",
       "3              word_could    word_cancer      word_google  \n",
       "4            word_climate      word_mers     word_climate  \n",
       "5                 word_us      word_drug     word_twitter  \n",
       "6            word_billion    word_health        word_deal  \n",
       "7          word_obamacare       word_cdc  word_kardashian  \n",
       "8              word_apple     word_cases         word_ceo  \n",
       "9                word_ceo  word_outbreak        word_bank  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.7 コードを段落に分ける\n",
    "logreg_coef = clf.coef_\n",
    "\n",
    "coef_rank_dataframe = pd.DataFrame()\n",
    "columns = np.array(df_train.columns)[:-1] # 'category'を除く\n",
    "categories = ['b(business)', 't(science and technology)', 'e(entertainment)', 'm(health)']\n",
    "\n",
    "idx_for_rank = np.argsort(logreg_coef, axis=1)\n",
    "coef_rank = columns[idx_for_rank]\n",
    "# 2.2 汎用的な名前を避ける（ループイテレータ）\n",
    "for categ_idx in range(4):\n",
    "    coef_rank_dataframe[categories[categ_idx] + '_top']     = coef_rank[categ_idx][-10:][::-1]\n",
    "    coef_rank_dataframe[categories[categ_idx] + '_bottom']  = coef_rank[categ_idx][:10]\n",
    "display(coef_rank_dataframe)\n",
    "\n",
    "\"\"\"\n",
    "b(business)_top\tb(business)_bottom\tt(science and technology)_top\tt(science and technology)_bottom\te(entertainment)_top\te(entertainment)_bottom\tm(health)_top\tm(health)_bottom\n",
    "0\tword_bank\tword_ebola\tword_google\tword_stocks\tword_kardashian\tword_google\tword_ebola\tword_facebook\n",
    "1\tword_obamacare\tword_aereo\tword_facebook\tword_fed\tword_cannes\tword_study\tword_study\tword_gm\n",
    "2\tword_fed\tword_microsoft\tword_apple\tword_american\tword_film\tword_facebook\tword_fda\tword_apple\n",
    "3\tword_stocks\tword_apple\tword_microsoft\tword_shares\tword_kim\tword_could\tword_cancer\tword_google\n",
    "4\tword_ukraine\tword_samsung\tword_climate\tword_drug\tword_star\tword_climate\tword_mers\tword_climate\n",
    "5\tword_ecb\tword_fda\tword_tesla\tword_ecb\tword_thrones\tword_us\tword_drug\tword_twitter\n",
    "6\tword_china\tword_facebook\tword_gm\tword_cancer\tword_miley\tword_billion\tword_health\tword_deal\n",
    "7\tword_oil\tword_google\tword_nasa\tword_ebola\tword_chris\tword_obamacare\tword_cdc\tword_kardashian\n",
    "8\tword_euro\tword_drug\tword_fcc\tword_day\tword_cyrus\tword_apple\tword_cases\tword_ceo\n",
    "9\tword_mcdonald\tword_mers\tword_earth\tword_percent\tword_show\tword_ceo\tword_outbreak\tword_bank\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egotMOGdG8IH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvpj1pdZKaiJ"
   },
   "source": [
    "## 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [03:21<04:54, 29.43s/it] C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 40%|████      | 6/15 [03:43<04:03, 27.03s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 47%|████▋     | 7/15 [04:07<03:28, 26.05s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 53%|█████▎    | 8/15 [04:33<03:01, 25.89s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 60%|██████    | 9/15 [04:58<02:34, 25.79s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 67%|██████▋   | 10/15 [05:24<02:09, 25.87s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 73%|███████▎  | 11/15 [05:51<01:43, 25.97s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 80%|████████  | 12/15 [06:17<01:18, 26.08s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 87%|████████▋ | 13/15 [06:45<00:53, 26.67s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 93%|█████████▎| 14/15 [07:11<00:26, 26.36s/it]C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "                                               \r"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "regularization_params = [10**i for i in range(-5, 10)]\n",
    "accuracy_dict = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "for C in tqdm(regularization_params, leave=False):\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, C=C).fit(X['train'], y['train'])\n",
    "\n",
    "    for kind_of_data in tqdm(['train', 'valid', 'test'], leave=False):\n",
    "        # 8.1 説明変数：printする前に計算した正解率を変数accuracyに代入\n",
    "        # 6.7 名前付き引数\n",
    "        accuracy = ComputeAccuracy(\n",
    "                                    y_true=y[kind_of_data],\n",
    "                                    y_pred=clf.predict(X[kind_of_data])\n",
    "                                )\n",
    "        accuracy_dict[kind_of_data].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAv2klEQVR4nO3deXxU9bn48c93JjOTPYGEBMIWQPaAQBDErUFrxVbFve4/tYq/Vmxf7W2rtvcW9ba/6vW2t+2t1lalaq2mFpei0kKtidi6sW8hgYABEsKWhJA9mZnn98cMMITsnMlkZp7363VeZ8453/OcJ5PMMydn+R4jIiillAp/tlAnoJRSyhpa0JVSKkJoQVdKqQihBV0ppSKEFnSllIoQWtCVUipCxIRqw+np6ZKdnd2ndRsaGkhISLA2IY0btJjhFjeccg23uOGU60CNu27duiMiMqTDhSISkiE3N1f6qqCgoM/ratz+jxluccMp13CLG065DtS4wFrppK7qIRellIoQWtCVUipCaEFXSqkIEbKToh1pa2ujvLyc5ubmLtulpKSwfft2y7ffn3FjY2MZMWIEDofD8u0ppaJTtwXdGLMUuAI4JCI5HSw3wC+BLwONwJ0isr4vyZSXl5OUlER2dja+sB2rq6sjKSmpL5voUn/FFRGqqqooLy9nzJgxlm9PKRWdenLI5QVgQRfLLwfG+4dFwG/6mkxzczNpaWldFvNIYIwhLS2t2/9ElFKqN7rdQxeR1caY7C6aLARe8l9O84kxJtUYM0xEKvuSUKQX8+Oi5ecMNyKC2ys0t3kA8IrgFd9YvMenffMEQSSgjTdw2jcPTq6/95iHrRW1J+IebyuAiP8SYvxx/G0QTmzLe7zN8WkvCLD1kJu2ooOWvxfBiBtOuQYz7tFGr+UxAYz0oD90f0F/p5NDLu8Aj4vIP/3T/wAeFJG1HbRdhG8vnszMzNz8/PxTlqekpHDWWWd1m4/H48Fut3fbrreqq6t5/fXXuffee3u13nXXXcfzzz9Pampqh8s7y7e0tJTa2tq+pApAfX09iYmJfV6/v2IGI66I8HGlh/KjzdhinLi9gtuLbxBOnfaCWwKnJaAdp62rVLB9dZxw+fi+fR7mz5+/TkRmd7SsX0+KisjvgN8BzJ49W/Ly8k5Zvn379h4dww7Wse49e/awdOlSvvOd75wy3+12ExPT+Vu1atWqLuN2lm9sbCwzZ87sW7JAYWEh7d/DMxWMmFbH9XqFf//LVl7ZvBcwxNjcOOw2nDE239huTr52+MbxMTacdhuOwGX+ecenj88r31vGuLFjsRmDzYDNGIx/bDNgsxkMvv+yOmxj843h+Dq+Ntu2bWPatBxfW8BmA4OB4+tzMo4xvmU2c3w7/nnt22FYt24ts2d3+Pk+I2vXWh83GDHDMe7ubeuD8jmzoqBXACMDpkf454WdJUuWsGvXLmbMmIHD4SA2NpZBgwZRXFzMjh07uPrqq9m3bx/Nzc1861vfYtGiRQBkZ2ezdu1a6uvrufzyy7ngggv46KOPGD58OH/5y19C/FNFljaPl+/9eRNvbdzP1/PGcY6rkovnz7d0G4WF+8nL6/4/xd6Kqyohb+pQy+NWldrJGZ5iedwjO62PG4yY4Rk3OIdcrSjoy4HFxph8YC5Q29fj54EefXsbRfuPdbisr4dcpmQls+TKqZ1v89FHKSkpYePGjRQWFvKVr3yFrVu3nrgSZenSpQwePJimpibOOeccrrvuOtLS0k6JsXPnTl599VWeffZZbrzxRl5//XUWLlzY61zV6ZrbPDzw6gb+XnSQ7102kfvnn0Vh4YFQp6XUgNGTyxZfBfKAdGNMObAEcACIyDPACnyXLJbiu2zxrmAl29/mzJlzymWFv/rVr3jzzTcB2LdvHzt37jytoI8ZM4YZM2YAkJubS1lZWX+lG9EaW90semkd/yw9wmMLp3LHvOxQp6TUgNOTq1xu7ma5APdblpFfV3vSwTqG3l5gb2iFhYW89957fPzxx8THx5OXl9fhZYcul+vEa7vdTlNTU9DzjHS1TW3c/cIaNuyt4b9vOJvrc0eEOiWlBqQBdadoqCUmJlJXV9fhstraWgYNGkR8fDzFxcV88skn/ZxddDpS38Idz3/GzkN1PHXLLC6fNizUKSk1YGlBD5CWlsb5559PTk4OcXFxZGZmnli2YMECnnnmGSZPnszEiRM599xzQ5hpdKisbeK25z6l4mgTz94xm7yJGaFOSakBTQt6O6+88kqH810uF3/96187XHb8OHl6ejpbt249Mf+73/0uQKd7/apze6oauPW5Tzna2MZLd89lzpjBoU5JqQFPC7oacHYcrOO25z6lzePllXvnMn1EaqhTUiosaEFXA8qW8lruWPopDruNP903jwmZwT/5rVSk0IKuBozPPq/m7hfWkBrv4I/3zGV0mvXPclQqkmlBVwNCYckh/u/L68hKjeOP98xlWEpcqFNSKuxoQVch99ctlXwzfwPjM5J46WtzSE90db+SUuo0WtBVSL2+rpzvLdvEjJGp/P6uOaTE6ROclOorfaboGTjeHez+/fu5/vrrO2yTl5fH+vV9eoBTxHvp4zL+7c+bmDcujT98ba4Wc6XOkO6hWyArK4tly5aFOo2w8lRBKU+uLOHSKZn8780ziXVY37+9UtFG99ADLFmyhKeeeurE9COPPMKPf/xjLrnkEmbNmsW0adM67A63rKyMnBzfsz+ampq46aabmDx5Mtdcc4325dKOiPDE34p5cmUJC2dk8fSts7SYK2WRgbuH/teH4MCWDhfFedxg70PqQ6fB5Y93uvjaa6/lhz/8Ifff7+tr7LXXXmPlypV885vfJDk5mSNHjnDuuedy1VVXdfoIud/85jfEx8ezfft2Nm/ezKxZs3qfZ4TyeoUly7fxh0/2cMvcUfx4YQ42mz6KTymrDNyCHgJnn302hw4dYv/+/Rw+fJhBgwYxdOhQvv3tb7N69WpsNhsVFRUcPHiQoUM7flDB6tWr+eY3vwnA9OnTmT59en/+CAOWxyt898+beGNDBYsuGsvDl0/S56oqZbGBW9C72JNuCmL3uTfccAPLli3jwIEDfPWrX+WPf/wjhw8fZt26dTgcDrKzszvsNld1rsXt4elNLaw7WMG/XTqBxRefpcVcqSDQY+jtfPWrXyU/P59ly5Zxww03UFtbS0ZGBg6Hg4KCAvbs2dPl+hdddNGJDr62bt3K5s2b+yPtAe0Hb2xl3UEPP7piCg9cMl6LuVJBMnD30ENk6tSp1NXVMXz4cIYNG8att97KlVdeybRp05g9ezaTJk3qcv2vf/3r3HXXXUyePJnJkyeTm5vbT5kPTDUNrSzfVMEXR8Vw9wVjul9BKdVnWtA7sGXLyZOx6enpfPzxxx22q6+vB3wPiT7ebW5cXBz5+fmntIvm7nPf2VJJm0e4cIT+qSkVbHrIRQXVWxsqmJiZxKgk/VNTKtj0U6aCZk9VA+v21HD1zOF63FypfqAFXQXNWxv2YwwsnJEV6lSUigp6YFMFhYjw5oZyzh2TRlZqHDus3kBrA2zKZ+TeTfDZTnAmgjMBXIknXzsTTr6OiYX++C/B6wV3s29oa/KPG6GtmZSjW2G3AfH42okHvJ52497PH15+CIobYdBoSB3tew9UVNKCroJi476jlFU18o28s6wN3NaMZ+3z/GXtr3g63sYxmw3X1vdwiRArgsvrH/uH2MCxcRBriyHW5sRld+Kyu4iNicUVE0tsTDwuRwKxjgSajtSw5a/LwdMC7hb/uPXU155m/7glYNwCnrZOUzcGPik2tBhDszG02Gy+sQmYZwzNtpPT7eed0s7YaDEGO0LSv1aQ6BUSvV6STAyJMfEkOpNIihtEYnwGiYlDSU4eSWLKaBJjU0hyJpHoSCTJmUSCI4EYm5aCSKC/RRUUb22owBVjY8G0ju+o7TVPG2x4mfUfPcnjsR62JzuZkTyOHO9w0jNSaWlroKWtkWZ3Ey3uJprdzVR7WmjxtNLsbaXF66ZF3DSLhzY8QJNv8AKt/iHQoS5ysfsH5/EZDv9w5nvGvi8bFy67k1i7C5fdRZzdhSsmlkHHv4DssSe+iFwxcewr20lyio26xirqWmqoba2nwtNMXdsR6tsO01K/s+ufB4izu0hyJJLoSiHRmUiSI4nGo43841//ID4mnnhH/CnjOEecbzpgXoIjgXhHPHExcdhM9B7NFRHcXjdt3raTg6ftlOk6T3CufNOCHuDo0aP84Q9/4Bvf+Eav1/3FL37BokWLiI+PD0Jm4aXN4+XtzZV8cUomybFn2CWu1wNb/kzlB/+Pn9vr+VtKApnONP7r3B+wIHsBH3zwAXkX5vUqpMfrocXTcmJodjf7xp5mWtzNrF3/KTnTZ4DFR2i2bdnGOTPP8RdlF7H2WFwxrhP/KThtzj6dPC6sLyQvL6/jhR43bbV7qDtcQn3NLuqOllF/rJz6+krqGg5T31ZHnc1Qb7NRb6uizh5DnTOe2hgHdR4PlaVbacRLIx7cvcgpDhtx2Ig3NuLxD8aGaXHz+j4nXgQP4EXwAh7xj/3TbuT0Nqe0PbnMA3jFS8yLNmwY7Mb4xhhs5vjYFjBtOzG2G5tvmTHYTpn2jevqG8hf9iRu8dImHto6GLeK55R5brzdvj+3J3yRK7myF+9oz/SooBtjFgC/xLdf8pyIPN5u+WhgKTAEqAZuE5Fyi3MNutraWp5++uk+F/TbbrtNCzqwesdhqhtauWbG8L4H8Xqh+G2aCn7C79sO8PvUFMSWwten3cNd0+4mLqbvj6iz2+zE23x7lh1pTGjiopEX9Tl+Z7ylXmYPnW153C7ZY3AMHsfgweMY3NHytiY4ug+O7oGasoDxPuqP1ZCYcPK5rm0IjUCjOTluQGg00OgfN50yLTQa35dBo4F6hAbjJaatFRu+YhI4jsHgAmxy+jI7xjeWjuYb3G0ebDG+wu7Fe6LIe45/MbT7wvCc8oUBbgMejG+ZAS8Gj/Ftz9EsOBAcAnEiOER8/5Mdfy2+Zb42glMClvnXc4gQE7CeM6s3X489121BN8bYgaeAS4FyYI0xZrmIFAU0+2/gJRF50RhzMfBT4PZgJBxMS5YsYdeuXcyYMYNLL72UjIwMXnvtNVpaWrjmmmt49NFHaWho4MYbb6S8vByPx8N//Md/cPDgQfbv38/8+fNJT0+noKAg1D9KSL2xoYJB8Q6+MHFI71cWgZ1/R95/jL/V7eJn6ekctKVwefYCvp37HYYlDrM+4WjmiIMhE3xDO2sLT93zdwAp/qGvCgu7+G8iVHFFOjjZ7AHx8q9//pPzzz/f0lwBVn+y1vKY0LM99DlAqYjsBjDG5AMLgcCCPgX4jv91AfDWmSb2xGdPUFxd3OEyj8eD3d77PrQnDZ7Eg3Me7HT5o48+SklJCRs3bmTVqlUsW7aMzz77DBHhqquuYvXq1Rw+fJisrCzeffddwLdXn5KSws9//nMKCgpIT0/vdV6R5FhzG+8VHeSr54zEYe/lcdTPP4T3/5NtB9fzROYwNmSkM3nwZJ6Y8yC5mdHdhYIKImP83XGfXg7bnMmQkGb5Jr324Dw3tyefuOHAvoDpcv+8QJuAa/2vrwGSjDHWvwv9aNWqVaxatYqZM2cya9YsiouL2blzJ9OmTePvf/87Dz74IB9++CEpKWeyvxJ5/rb1AC1uL1fP7MXhlvK18NJCjrx8Ff/hruDm4cPYkziYx857jFe/8qoWc6V6yIhI1w2MuR5YICL3+KdvB+aKyOKANlnAr4ExwGrgOiBHRI62i7UIWASQmZmZ277Pk5SUFM46q/vL3Pq6h96dzz//nJtuuolPP/2UH/zgB5x11lncfffdp7Wrrq5m1apVvPjii3zhC1/goYceIicnhw8++IC0tNO/xzrLt7S0lNra2j7nW19ff+K5plY505hPfNZEdbPw+IVxp5zg6yhuQv3njPn8jyRXreHFQUN4NjWRViAvOY/LUi4jztb9cfKB+B5o3P6NGW1x58+fv05EOj4ZIyJdDsA8YGXA9MPAw120TwTKu4ubm5sr7RUVFZ02ryPHjh3rUbve+vzzz2XUqFEiIrJy5UqZM2eO1NXViYhIeXm5HDx4UCoqKqSpqUlERN5++21ZuHChiIjk5OTI7t27e5VvT3/ezhQUFJzR+lbHrKhplOyH3pH/+XtJ13EPlYi89n/EuyRZ/vHzMXL5y/Mk54UcWfzeYimrLeu3fPszpsYNXsxoiwuslU7qak+Ooa8BxhtjxgAVwE3ALYENjDHpQLWIeP0Ff2kfvnhCLi0tjfPPP5+cnBwuv/xybrnlFubNmwdAYmIiL7/8MqWlpXzve9/DZrPhcDj4zW9+A8CiRYtYsGABWVlZUXtSdPmm/YjANZ0dbqkpgw/+Cza9SmlsIk9MOodPWg4yLiGD357z35w3/Lx+zVepSNNtQRcRtzFmMbAS39VCS0VkmzHmMXzfFMuBPOCnxhjBd8jl/iDmHFTHH05x3Le+9a1TpseNG8dll1122noPPPAADzzwQFBzG8hEhDfXVzBrVCqj0xJOXVh3kPE7noHV71Frt/PUlAt5rWkPCdLEQ3Me4saJN+KwneH16kqpnl2HLiIrgBXt5v0o4PUyYJm1qalwsr2yjpKDdfznwqmnLvC44aWFDDmyg1enXsJTrRXUNe3hxgk3cv+M+0mNTQ1JvkpFIr1TVFnizQ3lxNgMV0xv17PiplfYeGwXD4+ZQnlDMXOHzeX753yfCYNOv+5ZKXVmtKCrM+bxCn/ZuJ+8iRkMSnCeXNDWRHPBT/n2sCw8Nhu/vOiXzB85X/tGVypIBlwPOtLNZZSRIpJ+zo93VXGoroVrZ7U7Gfrpb3mDYxwxXm5Pv52LR12sxVypIBpQBT02NpaqqqqIKnYdERGqqqqIjY0NdSqWeGNDOUmuGC6elHFyZlMNrf/8OUvTM5iVMYuzXBZ3o6uUOs2AOuQyYsQIysvLOXz4cJftmpubg1IM+zNubGwsI0aMsHxb/a2x1c3KrQe4YnoWsY6Am6f++T/8xeHhIG4em34frTvb90+rlLLagCroDoeDMWPGdNuusLCQmTNnWr79cIs7EPy96CANrR6uCTzcUltB26e/5flRI5mWNoF5WfP4YOcHoUtSqSgxoA65qPDz5oYKhqfGMSc7oHPWwp+yIt5JhbRw3/T79Li5Uv1EC7rqs8N1LXy48wgLZ2Rhs/mL9qFiPBv/yHMZw5k0eBIXjbC+X3GlVMe0oKs+e3vTfjxeOfVW//f/k5XJqZR5Glg0fZHunSvVj7Sgqz57a2MFU7OSGZ+Z5Jux91O8xe/wbOYIzko9i0tGXRLaBJWKMlrQVZ+UHqpnc3ntyb1zEXjvEf4xeCilbUe5d9q9Uf2gYKVCQT9xqk/e2lCBzcBVZ/tv9d+xEtn7Eb/LHE52cjaXZZ/egZlSKri0oKte83qFtzZWcMH4IWQkx/qev/jeI3yQkU1x82HumXYPdpv1DyBRSnVNC7rqtbV7aiivaeKamf69881/Qg5v57dDhjE8cThfHvvl0CaoVJTSgq567c0NFcQ57HxpylBoa4b3f8JHw6eytbGCe6bdo32bKxUiWtBVrzS3eXh3834W5AwlwRUDa55DjpXz2/QhDE0YysJxC0OdolJRSwu66pXCkkMca3Zz9czh0FwLH/43a8aey4Zju7k7524cdt07VypUtKCrXnlzQwXpiS7OH5cG//olNNXwu0GppMelc+34a0OdnlJRTQu66rGjja28X3yIhTOyiGk4CB8/zcbJl/FpdRF3Tr0Tl90V6hSVimpa0FWPvbulkjaP/1b/D54Ar5tnkuIY5BrEDRNuCHV6SkU9Leiqx97aUMH4jESmOg/C+pfYeva1/Ovweu6YegfxjvhQp6dU1NOCrnpkX3Uja8pquHrmcEzBj8ERx2/jDMnOZG6edHOo01NKoQVd9dBbGyoAuGHoASj6CyW5t1JY+RG3TbmNBEdCiLNTSoEWdNUDIsKbGyqYmz2IjE8fh/h0futoJtGRyK2Tbw11ekopPy3oqluby2vZfaSBr48sg7IP2XXuvby3r5CbJ91MsjM51Okppfx6VNCNMQuMMSXGmFJjzEMdLB9ljCkwxmwwxmw2xmhnHhHkzQ0VuGLgwj1PwaBsfidVxMbEcvuU20OdmlIqQLcF3RhjB54CLgemADcbY6a0a/bvwGsiMhO4CXja6kRVaLR5vLy9aT8PDd+K/dBW9pz3Df62ZxU3TbyJQbGDQp2eUipAT/bQ5wClIrJbRFqBfKB9hx0CHP/fOwXYb12KKpT+ufMIdQ0N3FT3IgydzrMte3HYHNwx9Y5Qp6aUaqcnBX04sC9gutw/L9AjwG3GmHJgBfCAJdmpkHtjQwVfiyskrrGC8gse4J3d73L9hOtJj0sPdWpKqXaMiHTdwJjrgQUico9/+nZgrogsDmjzHX+snxlj5gHPAzki4m0XaxGwCCAzMzM3Pz+/T0nX19eTmJjYp3U1bs9jNrmFH7x/hNWub+NOGcPDI6fyaf2nLBm+hNSY1JDnGqy44ZRruMUNp1wHatz58+evE5HZHS4UkS4HYB6wMmD6YeDhdm22ASMDpncDGV3Fzc3Nlb4qKCjo87oat+cx/7x2n/zih3eKLEmWytK/y8yXZspjHz12xnGtFOz3QOMO/JjRFhdYK53U1Z4cclkDjDfGjDHGOPGd9Fzers1e4BIAY8xkIBY43JtvHTXw/GPtFu6NWYFMvYbfH1mDiPC1aV8LdVpKqU50W9BFxA0sBlYC2/FdzbLNGPOYMeYqf7N/A+41xmwCXgXu9H+TqDB1oLaZeeXP4zJtVJ23mNd3vs6V464kKzEr1KkppToR05NGIrIC38nOwHk/CnhdBJxvbWoqlAo++pibbe/TMPU2XthfSJu3jXum3RPqtJRSXdA7RVWHhq3/GR4Tgzvvfl7b8RpfHvNlRiWPCnVaSqku9GgPXUWXzzf/k7y2D9k89l4K9v6NZncz906/N9RpKaW6oXvo6nTvPUK1JJJ86Td4tfhVvpT9JcamjA11VkqpbugeujpFStUGxhxbw6uDv07Nwb/R0NbAvdN071ypcKB76Ookr5fhO1+iXNJxnX8HL29/mfkj5zNx8MRQZ6aU6gHdQ49WrY1wdC8c3QM1e6CmDA4Xk9G8m4dZzKiYD6lrreO+s+8LdaZKqR7Sgh6pPG44Vu4r1seL9lF/4a7ZAw2HTm0fE4c3dRSvei6lJecKXin+PhcMv4CpaVNDkr5Sqve0oIcrERytR2HfGl+RPlp2avGuLQfxnGxv7JAyAgaNhgmX+cap2bQlj2SXO50tNU4+LK1iefl+7hq6gaNlR7lvuu6dKxVOtKAft+rfufCTZ+FfdstDX+jxWB/X28b5nlb4KGBeQoavUI+cA9Nu8Bft0b5x8giOtQlF+4/5hspjFG04xs5D1bR5qgCIc9iZPdRLwYHXmDtsLjMyZlibs1IqqLSgH1e0nKa4TBKnX2l56P37yhk5coS1QW12dh5sYvycL/qKduoocMYDvg7XKmubKdp/jG27j1FUeYSiyt3sq246sXp6opMpWSl8YeIQpgxLZkpWMtlpCfz4ncdYVlPFk9OftDZfpVTQaUEHaKqBo3s4NOZ2Ei/7ieXhdxUWMjIvz/K4FYWFZI+7iN2HGyjaVs22ijLfnnflMY42tgFgDIxJS2D6iFRuOmcUU7N8xTsjKfa0eK2eVt479h6zMmZxztBzLM9XKRVcWtABDmwB4I3qkVS/ucXy8Pv3t7Cqxtq4LW1e1pU2sf+9lbS6fd3Ou2JsTBqaxOU5Q0/sdU8amkyCq+Nfc5unjV21uyiuLqa4uphNhzZx1HNUr2xRKkxpQQeo3AzAa4dH4m04aHn41lYPW2usjRtjMwx2wJ3nZZ8o3mPTE4ixd3xrwbHWY5RUl1BSXcL26u2UVJewq3YXbq8bgLiYOCYMmsAVqVcwb9g8S3NVSvUPLeiAZ/8mjsggZo9O5+n7vmh5/MLCQvKCcMjFF3fyKfNEhAMNB3x73TXFlFSXUFxdTEV9xYk26XHpTBw8kQuGX8CktElMGjSJkUkjsdvsFBYWYoyxPFelVPBpQQfaKjayxZvN6OTwunHWIx521Ow4UbRLqksorimmtqUWAINhdPJopqVP4/oJ1zNp8CQmDZ6kzwNVKkJpQW9txFlTyp+T51Hm/QWb3l1q+SaOHTvG7979naUxWzwt7K7ZjXuv75CJy+5ifOp4Lh19KZMGTWLi4IlMGDSBeEe8pdtVSg1cWtAPFWHDy8bUozjExhiXxZcXAm6bm2RXsqUxY0wMIz0jufTsS5k0eBKjk0cTY9Nfp1LRTCtA5SbqjaHRWcdXEr/C41983PJNBPUY+ljr4yqlwlN4HTQOAm/lZtY4fXvPI10jQ5yNUkr1XdQX9NbyDXzgzABglFMfsaaUCl/RXdA9bTiObGezK5a02EyS7Emhzkgppfosugv6kR3Yva1UuNycPUS7iVVKhbfoLuiVmzlmMzQ6G8hJzwl1NkopdUaiuqBL5SY2OhMA9EEOSqmwF9UFvaV8I6udQwCYkjYlxNkopdSZ6VFBN8YsMMaUGGNKjTEPdbD8f4wxG/3DDmPMUcsztZoI9kNb2eiMY0jsMFJjU0OdkVJKnZFubywyxtiBp4BLgXJgjTFmuYgUHW8jIt8OaP8AMDMIuVqrpgxHWx37XB7m6QlRpVQE6Mke+hygVER2i0grkA8s7KL9zcCrViQXVJWbqLXZaHQ2MW2InhBVSoW/nhT04cC+gOly/7zTGGNGA2OA9888teCSys1scboAPX6ulIoMRkS6bmDM9cACEbnHP307MFdEFnfQ9kFghIg80EmsRcAigMzMzNz8/Pw+JV1fX09iYmKf1j1u0sZHWeo9zKtphidGPEG8Pd6SuB0Jp7jhlGuw4oZTruEWN5xyHahx58+fv05EZne4UES6HIB5wMqA6YeBhztpuwE4r7uYIkJubq70VUFBQZ/XPa75p+Pkhl/PkYvzL7M0bkfCKW445RqsuOGUa7jFDadcB2pcYK10Uld7cshlDTDeGDPGGOMEbgKWt29kjJkEDAI+7vVXTn+rO4Cr+TB7XB6mZ+gJUaVUZOi2oIuIG1gMrAS2A6+JyDZjzGPGmKsCmt4E5Pu/QQa2ys1U22w0OlqYridElVIRokf9oYvICmBFu3k/ajf9iHVpBdmBTRS5nIDeIaqUihxReadoa/lG/uUYDMDktMndtFZKqfAQlU8s8uzfzPq4BDJiM0hyape5SqnIEH176M21xNXvpcwlTB+i158rpSJH9BX0A1s4YrPR6GhlRua0UGejlFKWib6CXqknRJVSkSnqCnpb+UY+cyYDRk+IKqUiStSdFG2r2MQ6VxKZscNIcCSEOh2llLJMdO2htzURW1vKbhdM0y5zlVIRJroK+qEijtigMaaN3KHTQ52NUkpZKroKeuVmipz+E6LpuoeulIosUVXQ3RUbWe9KwGCYOGhiqNNRSilLRdVJ0ZbyjaxxJpERO4J4R3yo01FKKUtFzx66x42zaju7XYZp6drDolIq8kRPQa/aSZVx0xjj5pwsPSGqlIo80VPQKzezzX+HqD5DVCkViaKmoHv2b2SzMxaDjYmD9YSoUiryRE1Bb963gbWuZDJjRxMXExfqdJRSynLRUdBFiDm8jZ1Om15/rpSKWNFR0I/uoUoaaIrxMDfr7FBno5RSQREdBb1yM9v8d4jm6B66UipCRUVBl8pNbHW6MNiZMHhCqNNRSqmgiIqC3rR3PWtdSWTGZuOyu0KdjlJKBUVUFHRzcAs7XHa9/lwpFdEiv6DXH+KIu5pmu5dzh+sJUaVU5Ir8gh7QZe70DO3DRSkVuSK+oEvlJra5XNiIYXzq+FCno5RSQdOjgm6MWWCMKTHGlBpjHuqkzY3GmCJjzDZjzCvWptl3TXvXs86ZQEbsGJx2Z6jTUUqpoOm2P3RjjB14CrgUKAfWGGOWi0hRQJvxwMPA+SJSY4zJCFbCvSWVm9mRFsO8wZNDnYpSSgVVT/bQ5wClIrJbRFqBfGBhuzb3Ak+JSA2AiByyNs0+aq6lqmU/zXbhvBEzQp2NUkoFlRGRrhsYcz2wQETu8U/fDswVkcUBbd4CdgDnA3bgERH5WwexFgGLADIzM3Pz8/P7lHR9fT2JiYndtks5uo0DO3/M9zPSeXDYg4xwjrAkbm+FU9xwyjVYccMp13CLG065DtS48+fPXycisztcKCJdDsD1wHMB07cDv27X5h3gTcABjAH2Aaldxc3NzZW+Kigo6FnDj5+WJ385Sqa/MENaPa3Wxe2lcIobTrkGK2445RpuccMp14EaF1grndTVnhxyqQBGBkyP8M8LVA4sF5E2Efkc3956yC8padq3gY3OeIa4xuKwOUKdjlJKBVVPCvoaYLwxZowxxgncBCxv1+YtIA/AGJMOTAB2W5dm37SVb6DYFcOUwXqHqFIq8nVb0EXEDSwGVgLbgddEZJsx5jFjzFX+ZiuBKmNMEVAAfE9EqoKVdI+0NXOkcQ8tNpg3Qu8QVUpFvm4vWwQQkRXAinbzfhTwWoDv+IeB4VARRU47ALnD9KHQSqnIF7l3ih7wPRTaLg7GpowNdTZKKRV0EVvQW/ZtZIszjnTXWGJsPfpHRCmlwlrEFvSm8vUUuxxM0hOiSqkoEZkF3evhYF0pLTY4T0+IKqWiRGQW9CM7KfFfdj5HHwqtlIoSkVnQD/j6QLeLgzEpY0KdjVJK9YuILOhtFRvZ4nKR7hyH3WYPdTpKKdUvIrKg1+1dT7HTyUQ9IaqUiiKRV9BFqDxaRKsNztUTokqpKBJ5Bf3oXnba3QCcr32gK6WiSOQVdP8dojHiIDslO9TZKKVUv4m4gu6u2Mg2p5M0xzhsJuJ+PKWU6lTEVbxje3wnRMcPmhrqVJRSql9FXEHfW7ONNpvRLnOVUlEnsgp6/WF2Uw/ARaNnhjgZpZTqX5FV0A9sYpvLiUOcjEoeFepslFKqX0VUQffs9xX0tJixekJUKRV1Iqrq1Zato8TpZNzgnFCnopRS/S6iCvruqi24jWGu9rColIpCkVPQm4/xudf3XOr52bNCnIxSSvW/yCnoB7eyzenC6XUyOmVkqLNRSql+FzEF3bt/E0UuJ4NjxmCMCXU6SinV7yKmoFeXrWWn08HY1GmhTkUppUIiYgp66eFNuI1hzvAZoU5FKaVCIjIKuruFMvcBAC4ZqydElVLRqUcF3RizwBhTYowpNcY81MHyO40xh40xG/3DPdan2oVDRWx3OnB6XYxOGdGvm1ZKqYEiprsGxhg78BRwKVAOrDHGLBeRonZN/yQii4OQY7ekcrOvy1z7aD0hqpSKWj3ZQ58DlIrIbhFpBfKBhcFNq3eq96yh1OlgdKreUKSUil5GRLpuYMz1wAIRucc/fTswN3Bv3BhzJ/BT4DCwA/i2iOzrINYiYBFAZmZmbn5+fp+Srq+vJzEx8cS0d/13+VZaC1fE3c1lGX3vZbF9XKuEU9xwyjVYccMp13CLG065DtS48+fPXycisztcKCJdDsD1wHMB07cDv27XJg1w+V/fB7zfXdzc3Fzpq4KCgpMTHrf84WejJeeFHNldva/PMU+La6FwihtOuQYrbjjlGm5xwynXgRoXWCud1NWeHHKpAAJvvRzhnxf4pVAlIi3+yeeA3J5911igqpRipyHW4yI7dXi/bVYppQaanhT0NcB4Y8wYY4wTuAlYHtjAGDMsYPIqYLt1KXaj0vdQ6MG2UXpCVCkV1bq9ykVE3MaYxcBKwA4sFZFtxpjH8O36Lwe+aYy5CnAD1cCdQcz5FNV71rDb4WB26oz+2qRSSg1I3RZ0ABFZAaxoN+9HAa8fBh62NrWe2bp/Ld5Yw2ztMlcpFeXC+05REXY37QXgS2edE+JklFIqtMK7oNeWsyPGS5zHxbjBWaHORimlQiq8C3rlJopcDtKM3u6vlFJhXdBr9n7GboeDrJQZoU5FKaVCLqwL+sbyNYgxzMzSHhaVUiqsC3ppQxkAl47rv/uYlFJqoArfgt5QxS57CwluFxOH6B2iSikVvgX9wCa2OZ0MRq9uUUopCOOCXrP3M8qcDoYl6w1FSikFYVzQ1+/9GIDpw+eEOBOllBoYwrag76zbDcAX9YSoUkoBYVrQ7e4mdpkGEt1OpmQM634FpZSKAmFZ0BMayihyORksWdplrlJK+YVlQad2O3sdDjKTpoU6E6WUGjDCsqCX1ZcAkJM1L8SZKKXUwBGWBX2fuxKAi8fqLf9KKXVc+BV0dyt77A0ktzmZPkxvKlJKqePCr6Af3u47Ieodis2mJ0SVUuq4sCvoNXs/ocIRQ0ZiTqhTUUqpASXsCvpHx44AMCnrghBnopRSA0vYFfR/eGMBuHicnhBVSqlAMaFOoLcmJV7C+wdsTM/SO0SVUipQ2BX0RefPYELbURz2sPvnQimlgkqrolJKRQgt6EopFSF6VNCNMQuMMSXGmFJjzENdtLvOGCPGmNnWpaiUUqonui3oxhg78BRwOTAFuNkYM6WDdknAt4BPrU5SKaVU93qyhz4HKBWR3SLSCuQDCzto95/AE0CzhfkppZTqISMiXTcw5npggYjc45++HZgrIosD2swCfigi1xljCoHvisjaDmItAhYBZGZm5ubn5/cp6fr6ehITE/u0rsbt/5jhFjeccg23uOGU60CNO3/+/HUi0vFhbRHpcgCuB54LmL4d+HXAtA0oBLL904XA7O7i5ubmSl8VFBT0eV2N2/8xwy1uOOUabnHDKdeBGhdYK53U1Z4ccqkARgZMj/DPOy4JyAEKjTFlwLnAcj0xqpRS/asnh1xigB3AJfgK+RrgFhHZ1kn7Qjo55NKu3WFgTx9yBkgHjvRxXY3b/zHDLW445RpuccMp14Ead7SIDOloQbd3ioqI2xizGFgJ2IGlIrLNGPMYvl3/5X3JqLOEesIYs1Y6O4Z0BjRueOUarLjhlGu4xQ2nXMMxbo9u/ReRFcCKdvN+1EnbvDNPSymlVG/pnaJKKRUhwrWg/07jBi1uOOUarLjhlGu4xQ2nXMMubrcnRZVSSoWHcN1DV0op1Y4WdKWUihBa0JVSKkJEXEE3xuQZYz40xjxjjMmzOHaCMWatMeYKi+JN9ue5zBjzdSti+uNebYx51hjzJ2PMlyyMO9YY87wxZpkFsRKMMS/687x1oOXXLm6w3s+g/P79sa3+Ww3K58oYYzPG/MQY87/GmP9jYdwL/bk+Z4z5yMK4o4wxbxljlnbVlXgvY04xxrxmjPmNv++svuusT4BQDMBS4BCwtd38BUAJUAo81E2MLwB/BV4AzrIqrr/9Y8D3gSusiikn+8N52cpc/esMAp4PQtxlZ/r7w9cn0JX+13+y8m+is/wsiHvi/bQ47onfv1VxA/9WrYjZ0efKorjXAC8CPwcuCcJ7ezVwn4X5fgW4zcq/W+DfgAv9r5f35DPY6XbPZGWrB+AiYFbgm4Dv7tRdwFjACWzC1y/7NOCddkMGYPOvlwn80cK4lwI3AXfiK+hnHNO/zlX+D8otVuUasN7PgFlBiNtZQe/NNh4GZvjbvGLF30R3+VkQ98T7aVXc9r9/iz4bp/ytWhTztM+VRXEfwl9wu/u99fF39hqQZGG+aUAB8D5wl0UxM/A9c+JJ4F99qZ3HhwH1kGgRWW2MyW43+0R/7ADGmHxgoYj8FF9h7UwN4LIqrv/fzAR8v4AmfHsWo840V/F1nbDcGPMuvsJmRa4GeBz4q4ist+o96E5vtgGU4+vobSNdHPrrZcyiYORqjNlOu/fTqnzb//4tiptIwN+qMWaFiHjPJKaIHH9vT3yuLMp1H9Dqb+OxMG6RMWYUUCsidRbGbQOW+NdZBvz+TGP6P2/3+x8m9EZXuXZnQBX0TgzH90s/rhyY21ljY8y1wGVAKvBrq+KKyA/98e8EjoiI11c3zyjXPOBafB+QFZ21621c4AHgi0CKMeYsEXnGirjGmDTgJ8BMY8zD/j/E7nS2jV8BvzbGfAV4uwdxuo3Zx/x6kmtP38/e5ptHz37/vYor/mcVBP6tWpBrTz9XvYoL/BL4X2PMhcBqC+MCfI1OCu4ZxH0GeMQYcwtQZkVMf+H/Ab4v4Sf7mC8QHgW9V0TkDc7wW66b+C9YGKsQX//xlhKRX+ErmFbHrQL+r0WxGoC7rIgVENOy/NrFDdb7WUgQfv8B8V+wMFZQPlci0oiv8FpORJYEIeZWfM+IsDJmGf4H/5ypcLjKpbv+2AdS3HDKNZhxg72NcHs/wiluOOUabnGD/3k7kwPwwRiAbE49kRAD7AbGcPJEwtSBEDeccg1mXH2fwzduOOUabnH74/N22jatDHbGycCrQCW+Ew/lwNf887+M7yEbu/A9uzTkccMp12DG1fc5fOOGU67hFrc/Pm8dDdo5l1JKRYhwOIaulFKqB7SgK6VUhNCCrpRSEUILulJKRQgt6EopFSG0oCulVITQgq6UUhFCC7pSSkUILehKKRUh/j/pEYzdfiWqMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    plt.plot(regularization_params, accuracy_dict[kind_of_data], label=kind_of_data)\n",
    "plt.xscale('log')\n",
    "plt.xticks(regularization_params)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('../figures/chap06_logreg.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大値\n",
      "train:\t0.9997188905547226\n",
      "valid:\t0.9182908545727136\n",
      "test:\t0.9167916041979011\n"
     ]
    }
   ],
   "source": [
    "print('最大値')\n",
    "for k in ['train', 'valid', 'test']:\n",
    "    print(k +':\\t'+ str(np.max(accuracy_dict[k])))\n",
    "\"\"\"\n",
    "最大値\n",
    "train:\t0.9997188905547226\n",
    "valid:\t0.9182908545727136\n",
    "test:\t0.9167916041979011\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yON8wxx_KbcO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBw03yFJriv5"
   },
   "source": [
    "## 59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p7G47Fzrkkg"
   },
   "source": [
    "参考: <br> \n",
    "* [タイタニック号の乗客の生存予測〜80%以上の予測精度を超える方法（モデル構築＆推論編）](https://yolo-kiyoshi.com/2020/01/22/post-1588/)<br>\n",
    "* [Python のハイパーパラメータ自動最適化ライブラリー Optuna その2 Optunaを使うとき最低限覚えておきたい探索範囲の指定方法 –](https://www.salesanalytics.co.jp/datascience/datascience073/)<br>\n",
    "* [Optunaを用いたPyTorchにおけるハイパーパラメータチューニング](https://qiita.com/Yushi1958/items/cd22ade638f7e292e520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Me9xU1_isTza"
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeCrossEntropy(y_true, y_pred_proba, num_class):\n",
    "\n",
    "    y_true_hot = np.identity(num_class)[y_true.astype(int)]\n",
    "    proba = np.sum(y_pred_proba * y_true_hot, axis=1)\n",
    "\n",
    "    return -np.log(proba).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_CE(trial):\n",
    "\n",
    "    global X, y\n",
    "    C = trial.suggest_float('C', 0.01, 1000)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "\n",
    "    clf = LogisticRegression(C=C,\n",
    "                            solver=solver,\n",
    "                            random_state=0).fit(X['train'], y['train'])\n",
    "\n",
    "    # 8.1 説明変数：printする前に計算した正解率を変数accuracyに代入\n",
    "    # 6.7 名前付き引数\n",
    "    ce_loss = ComputeCrossEntropy(\n",
    "                                    y_true = y['valid'],\n",
    "                                    y_pred_proba = clf.predict_proba(X['valid']),\n",
    "                                    num_class=4\n",
    "                                )\n",
    "    return  ce_loss\n",
    "\n",
    "\n",
    "def objective_ACC(trial):\n",
    "\n",
    "    global X, y\n",
    "    C = trial.suggest_float('C', 0.01, 1000)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "\n",
    "    clf = LogisticRegression(C=C,\n",
    "                            solver=solver,\n",
    "                            random_state=0).fit(X['train'], y['train'])\n",
    "\n",
    "    # 8.1 説明変数：printする前に計算した正解率を変数accuracyに代入\n",
    "    # 6.7 名前付き引数\n",
    "    accuracy = ComputeAccuracy(\n",
    "                                y_true=y['valid'],\n",
    "                                y_pred=clf.predict(X['valid'])\n",
    "                            )\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8495170,
     "status": "ok",
     "timestamp": 1645699890122,
     "user": {
      "displayName": "田中義規",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03358882541309422843"
     },
     "user_tz": -540
    },
    "id": "_S6zAy16ruZq",
    "outputId": "7b981ac1-fca0-45bd-806b-31c7bdc5d6be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-01 18:00:49,061]\u001b[0m A new study created in memory with name: no-name-b5c4185f-07bb-4087-8290-bfcc43a709a8\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:01:14,600]\u001b[0m Trial 0 finished with value: 0.24364329172679172 and parameters: {'C': 162.14881371600282, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:01:16,621]\u001b[0m Trial 1 finished with value: 0.29850557968222124 and parameters: {'C': 675.3384683387015, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:01:18,533]\u001b[0m Trial 2 finished with value: 0.31025103620337746 and parameters: {'C': 918.784463113269, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:01:43,398]\u001b[0m Trial 3 finished with value: 0.2735974266216556 and parameters: {'C': 494.9311300602647, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:01:45,365]\u001b[0m Trial 4 finished with value: 0.310262304015556 and parameters: {'C': 914.3161884447014, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:02:10,134]\u001b[0m Trial 5 finished with value: 0.2753419618003836 and parameters: {'C': 269.37898419861824, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:02:12,212]\u001b[0m Trial 6 finished with value: 0.2776217076241403 and parameters: {'C': 374.2359195907372, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:02:14,698]\u001b[0m Trial 7 finished with value: 0.30671900640768784 and parameters: {'C': 823.0625099040776, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:02:16,745]\u001b[0m Trial 8 finished with value: 0.28272561803621965 and parameters: {'C': 434.5896231413493, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:02:18,526]\u001b[0m Trial 9 finished with value: 0.26572408280619964 and parameters: {'C': 252.3149301961297, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:02:42,516]\u001b[0m Trial 10 finished with value: 0.22582935865933965 and parameters: {'C': 29.6250283509911, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.22582935865933965.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:03:05,441]\u001b[0m Trial 11 finished with value: 0.22486801286393843 and parameters: {'C': 16.113160487843487, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:03:29,343]\u001b[0m Trial 12 finished with value: 0.22707740981929495 and parameters: {'C': 39.43326985149742, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:03:56,029]\u001b[0m Trial 13 finished with value: 0.22696273227507405 and parameters: {'C': 10.400288214429906, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:04:19,143]\u001b[0m Trial 14 finished with value: 0.24770520664986392 and parameters: {'C': 133.33341437913157, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:04:42,252]\u001b[0m Trial 15 finished with value: 0.2973730593530074 and parameters: {'C': 665.0396859717154, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:05:08,790]\u001b[0m Trial 16 finished with value: 0.2516065969495972 and parameters: {'C': 161.7267047351445, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:05:35,589]\u001b[0m Trial 17 finished with value: 0.2680982105962041 and parameters: {'C': 329.3508605310007, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:06:00,640]\u001b[0m Trial 18 finished with value: 0.26013179095603844 and parameters: {'C': 3.190291028375663, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:06:25,287]\u001b[0m Trial 19 finished with value: 0.3000260871277275 and parameters: {'C': 605.3275163175545, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:06:50,423]\u001b[0m Trial 20 finished with value: 0.23881220116917967 and parameters: {'C': 117.53319552895971, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:07:16,468]\u001b[0m Trial 21 finished with value: 0.22576682804076903 and parameters: {'C': 10.714728765080245, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:07:42,332]\u001b[0m Trial 22 finished with value: 0.238852428660118 and parameters: {'C': 74.12715253033593, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:08:06,457]\u001b[0m Trial 23 finished with value: 0.2663082384272814 and parameters: {'C': 215.50905887819113, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:08:30,911]\u001b[0m Trial 24 finished with value: 0.23666846075012196 and parameters: {'C': 83.62997931590928, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:08:53,913]\u001b[0m Trial 25 finished with value: 0.2567826201543603 and parameters: {'C': 217.98404485860158, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:09:16,094]\u001b[0m Trial 26 finished with value: 0.26919039502849323 and parameters: {'C': 329.4368223866112, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:09:38,787]\u001b[0m Trial 27 finished with value: 0.24196015394591844 and parameters: {'C': 76.53299627032058, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:10:02,101]\u001b[0m Trial 28 finished with value: 0.24693182715453865 and parameters: {'C': 183.2368280379556, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:10:25,923]\u001b[0m Trial 29 finished with value: 0.2538346403494974 and parameters: {'C': 124.4918226828216, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:10:50,696]\u001b[0m Trial 30 finished with value: 0.2282472052440248 and parameters: {'C': 9.111063760731469, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:11:13,562]\u001b[0m Trial 31 finished with value: 0.23100549282352548 and parameters: {'C': 7.876246953969595, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:11:36,255]\u001b[0m Trial 32 finished with value: 0.23585735430458993 and parameters: {'C': 63.551900847484305, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:12:00,999]\u001b[0m Trial 33 finished with value: 0.2446906571716228 and parameters: {'C': 142.7105682984547, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:12:27,936]\u001b[0m Trial 34 finished with value: 0.28376525516236933 and parameters: {'C': 2.0217661771081588, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:12:52,330]\u001b[0m Trial 35 finished with value: 0.23870265857226228 and parameters: {'C': 74.963483046546, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:12:54,225]\u001b[0m Trial 36 finished with value: 0.29019199970925874 and parameters: {'C': 543.4801981155754, 'solver': 'liblinear'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:13:16,113]\u001b[0m Trial 37 finished with value: 0.2732280472839468 and parameters: {'C': 287.12059559496186, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:13:38,831]\u001b[0m Trial 38 finished with value: 0.2490658953525396 and parameters: {'C': 169.96343421550466, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:13:40,741]\u001b[0m Trial 39 finished with value: 0.3051674793330398 and parameters: {'C': 810.07987872483, 'solver': 'liblinear'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:13:42,642]\u001b[0m Trial 40 finished with value: 0.26173737915167516 and parameters: {'C': 219.40120251927024, 'solver': 'liblinear'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:14:05,547]\u001b[0m Trial 41 finished with value: 0.2334429225176171 and parameters: {'C': 48.829383388596625, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:14:28,643]\u001b[0m Trial 42 finished with value: 0.22730662862742354 and parameters: {'C': 28.516676070090227, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:14:51,553]\u001b[0m Trial 43 finished with value: 0.24832499006120085 and parameters: {'C': 115.37299252884735, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:15:15,486]\u001b[0m Trial 44 finished with value: 0.3298300096855658 and parameters: {'C': 969.9978150932882, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:15:39,681]\u001b[0m Trial 45 finished with value: 0.2878626317087911 and parameters: {'C': 402.0054498793345, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:16:03,468]\u001b[0m Trial 46 finished with value: 0.2278748352861283 and parameters: {'C': 46.573782986848826, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:16:05,272]\u001b[0m Trial 47 finished with value: 0.2415515807757602 and parameters: {'C': 95.82556689094909, 'solver': 'liblinear'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:16:29,555]\u001b[0m Trial 48 finished with value: 0.24809170340344056 and parameters: {'C': 185.01700995236084, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.22486801286393843.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:16:53,209]\u001b[0m Trial 49 finished with value: 0.22358193987305136 and parameters: {'C': 41.12526644708382, 'solver': 'lbfgs'}. Best is trial 49 with value: 0.22358193987305136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 41.12526644708382, 'solver': 'lbfgs'}\n",
      "0.22358193987305136\n"
     ]
    }
   ],
   "source": [
    "study_ce = optuna.create_study(direction='minimize')\n",
    "study_ce.optimize(objective_CE, n_trials=50)\n",
    "print(study_ce.best_params)\n",
    "print(study_ce.best_value)\n",
    "best_ce_params = study_ce.best_params\n",
    "\"\"\"\n",
    "[I 2022-05-01 18:00:49,061] A new study created in memory with name: no-name-b5c4185f-07bb-4087-8290-bfcc43a709a8\n",
    "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:01:14,600] Trial 0 finished with value: 0.24364329172679172 and parameters: {'C': 162.14881371600282, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.24364329172679172.\n",
    "[I 2022-05-01 18:01:16,621] Trial 1 finished with value: 0.29850557968222124 and parameters: {'C': 675.3384683387015, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\n",
    "[I 2022-05-01 18:01:18,533] Trial 2 finished with value: 0.31025103620337746 and parameters: {'C': 918.784463113269, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\n",
    "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:01:43,398] Trial 3 finished with value: 0.2735974266216556 and parameters: {'C': 494.9311300602647, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.24364329172679172.\n",
    "[I 2022-05-01 18:01:45,365] Trial 4 finished with value: 0.310262304015556 and parameters: {'C': 914.3161884447014, 'solver': 'liblinear'}. Best is trial 0 with value: 0.24364329172679172.\n",
    "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "...\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:16:53,209] Trial 49 finished with value: 0.22358193987305136 and parameters: {'C': 41.12526644708382, 'solver': 'lbfgs'}. Best is trial 49 with value: 0.22358193987305136.\n",
    "{'C': 41.12526644708382, 'solver': 'lbfgs'}\n",
    "0.22358193987305136\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-01 18:16:53,436]\u001b[0m A new study created in memory with name: no-name-a2da79f6-8cd7-41f0-840f-fe7fe28b991e\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:16:55,255]\u001b[0m Trial 0 finished with value: 0.9182908545727136 and parameters: {'C': 752.5105754267239, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9182908545727136.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:16:56,986]\u001b[0m Trial 1 finished with value: 0.9190404797601199 and parameters: {'C': 122.23751142610944, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:16:58,802]\u001b[0m Trial 2 finished with value: 0.9175412293853074 and parameters: {'C': 581.1313192687813, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:17:20,513]\u001b[0m Trial 3 finished with value: 0.9160419790104948 and parameters: {'C': 594.387945478554, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:17:43,318]\u001b[0m Trial 4 finished with value: 0.9160419790104948 and parameters: {'C': 967.0024796256115, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:17:45,167]\u001b[0m Trial 5 finished with value: 0.9182908545727136 and parameters: {'C': 677.4189857751351, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:17:46,996]\u001b[0m Trial 6 finished with value: 0.9175412293853074 and parameters: {'C': 507.1235362729944, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:17:48,837]\u001b[0m Trial 7 finished with value: 0.9182908545727136 and parameters: {'C': 889.4918545997663, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:17:50,650]\u001b[0m Trial 8 finished with value: 0.9190404797601199 and parameters: {'C': 429.199192928996, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:17:52,364]\u001b[0m Trial 9 finished with value: 0.9175412293853074 and parameters: {'C': 49.53900825586984, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:18:15,464]\u001b[0m Trial 10 finished with value: 0.9175412293853074 and parameters: {'C': 100.10183634007934, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:17,259]\u001b[0m Trial 11 finished with value: 0.9190404797601199 and parameters: {'C': 278.34781568278277, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:19,032]\u001b[0m Trial 12 finished with value: 0.9190404797601199 and parameters: {'C': 299.5615736535397, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:20,807]\u001b[0m Trial 13 finished with value: 0.9190404797601199 and parameters: {'C': 255.62241443370442, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:18:43,069]\u001b[0m Trial 14 finished with value: 0.9145427286356822 and parameters: {'C': 388.85113096524066, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:44,815]\u001b[0m Trial 15 finished with value: 0.9205397301349325 and parameters: {'C': 147.85499072843322, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:46,607]\u001b[0m Trial 16 finished with value: 0.9205397301349325 and parameters: {'C': 160.56374027177108, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:18:48,410]\u001b[0m Trial 17 finished with value: 0.9197901049475262 and parameters: {'C': 200.37570013587097, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:19:10,741]\u001b[0m Trial 18 finished with value: 0.9190404797601199 and parameters: {'C': 169.8903673996971, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:12,439]\u001b[0m Trial 19 finished with value: 0.9152923538230885 and parameters: {'C': 7.870615209606058, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:14,208]\u001b[0m Trial 20 finished with value: 0.9190404797601199 and parameters: {'C': 357.2834350073098, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:15,975]\u001b[0m Trial 21 finished with value: 0.9197901049475262 and parameters: {'C': 195.58109590531612, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:17,765]\u001b[0m Trial 22 finished with value: 0.9197901049475262 and parameters: {'C': 200.0829429282105, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:19,552]\u001b[0m Trial 23 finished with value: 0.9190404797601199 and parameters: {'C': 84.98043340981297, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:21,425]\u001b[0m Trial 24 finished with value: 0.9197901049475262 and parameters: {'C': 332.42123156842104, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:23,205]\u001b[0m Trial 25 finished with value: 0.9182908545727136 and parameters: {'C': 474.37762640181893, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:19:44,986]\u001b[0m Trial 26 finished with value: 0.9160419790104948 and parameters: {'C': 226.32227261735792, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:46,784]\u001b[0m Trial 27 finished with value: 0.9197901049475262 and parameters: {'C': 339.0855521051159, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:48,562]\u001b[0m Trial 28 finished with value: 0.9197901049475262 and parameters: {'C': 140.9226585455081, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:50,353]\u001b[0m Trial 29 finished with value: 0.9190404797601199 and parameters: {'C': 402.02102028380136, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:52,078]\u001b[0m Trial 30 finished with value: 0.9145427286356822 and parameters: {'C': 15.222782959215493, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:53,858]\u001b[0m Trial 31 finished with value: 0.9190404797601199 and parameters: {'C': 228.49117561913528, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:55,658]\u001b[0m Trial 32 finished with value: 0.9197901049475262 and parameters: {'C': 139.5926847079409, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:57,454]\u001b[0m Trial 33 finished with value: 0.9190404797601199 and parameters: {'C': 93.17535017344473, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:19:59,193]\u001b[0m Trial 34 finished with value: 0.9205397301349325 and parameters: {'C': 152.59648733945264, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:01,040]\u001b[0m Trial 35 finished with value: 0.9197901049475262 and parameters: {'C': 125.74216410274093, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:20:24,291]\u001b[0m Trial 36 finished with value: 0.9160419790104948 and parameters: {'C': 67.91038568896727, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:26,385]\u001b[0m Trial 37 finished with value: 0.9182908545727136 and parameters: {'C': 618.7667838983789, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:28,245]\u001b[0m Trial 38 finished with value: 0.9197901049475262 and parameters: {'C': 294.130033468466, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:30,097]\u001b[0m Trial 39 finished with value: 0.9182908545727136 and parameters: {'C': 751.8158187698157, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:20:52,470]\u001b[0m Trial 40 finished with value: 0.9160419790104948 and parameters: {'C': 521.583295776283, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:54,267]\u001b[0m Trial 41 finished with value: 0.9190404797601199 and parameters: {'C': 318.0736763529308, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:56,053]\u001b[0m Trial 42 finished with value: 0.9197901049475262 and parameters: {'C': 165.28060823501588, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:57,832]\u001b[0m Trial 43 finished with value: 0.9190404797601199 and parameters: {'C': 252.59080033529156, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:20:59,668]\u001b[0m Trial 44 finished with value: 0.9197901049475262 and parameters: {'C': 178.41602930279225, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:21:01,535]\u001b[0m Trial 45 finished with value: 0.9197901049475262 and parameters: {'C': 161.54350741091415, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:21:03,285]\u001b[0m Trial 46 finished with value: 0.9175412293853074 and parameters: {'C': 47.047872211739204, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:21:05,062]\u001b[0m Trial 47 finished with value: 0.9190404797601199 and parameters: {'C': 120.13010379795466, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "\u001b[32m[I 2022-05-01 18:21:06,889]\u001b[0m Trial 48 finished with value: 0.9190404797601199 and parameters: {'C': 260.29148241928056, 'solver': 'liblinear'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-05-01 18:21:30,217]\u001b[0m Trial 49 finished with value: 0.9175412293853074 and parameters: {'C': 924.2387192047233, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 147.85499072843322, 'solver': 'liblinear'}\n",
      "0.9205397301349325\n"
     ]
    }
   ],
   "source": [
    "study_acc = optuna.create_study(direction='maximize')\n",
    "study_acc.optimize(objective_ACC, n_trials=50)\n",
    "print(study_acc.best_params)\n",
    "print(study_acc.best_value)\n",
    "best_acc_params = study_acc.best_params\n",
    "\"\"\"\n",
    "[I 2022-05-01 18:16:53,436] A new study created in memory with name: no-name-a2da79f6-8cd7-41f0-840f-fe7fe28b991e\n",
    "[I 2022-05-01 18:16:55,255] Trial 0 finished with value: 0.9182908545727136 and parameters: {'C': 752.5105754267239, 'solver': 'liblinear'}. Best is trial 0 with value: 0.9182908545727136.\n",
    "[I 2022-05-01 18:16:56,986] Trial 1 finished with value: 0.9190404797601199 and parameters: {'C': 122.23751142610944, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "[I 2022-05-01 18:16:58,802] Trial 2 finished with value: 0.9175412293853074 and parameters: {'C': 581.1313192687813, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:17:20,513] Trial 3 finished with value: 0.9160419790104948 and parameters: {'C': 594.387945478554, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:17:43,318] Trial 4 finished with value: 0.9160419790104948 and parameters: {'C': 967.0024796256115, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "[I 2022-05-01 18:17:45,167] Trial 5 finished with value: 0.9182908545727136 and parameters: {'C': 677.4189857751351, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "[I 2022-05-01 18:17:46,996] Trial 6 finished with value: 0.9175412293853074 and parameters: {'C': 507.1235362729944, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "[I 2022-05-01 18:17:48,837] Trial 7 finished with value: 0.9182908545727136 and parameters: {'C': 889.4918545997663, 'solver': 'liblinear'}. Best is trial 1 with value: 0.9190404797601199.\n",
    "...\n",
    "Please also refer to the documentation for alternative solver options:\n",
    "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "  n_iter_i = _check_optimize_result(\n",
    "[I 2022-05-01 18:21:30,217] Trial 49 finished with value: 0.9175412293853074 and parameters: {'C': 924.2387192047233, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.9205397301349325.\n",
    "{'C': 147.85499072843322, 'solver': 'liblinear'}\n",
    "0.9205397301349325\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "4mMvxSBHEaQu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 41.12526644708382, 'solver': 'lbfgs'}\n",
      "0.22358193987305136\n",
      "train:\t0.9985944527736131\n",
      "valid:\t0.9160419790104948\n",
      "test:\t0.9152923538230885\n"
     ]
    }
   ],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "# 6.7 名前付き引数\n",
    "clf_ce = LogisticRegression(\n",
    "                                random_state=0,\n",
    "                                C=best_ce_params['C'],\n",
    "                                solver=best_ce_params['solver']\n",
    "                        ).fit(X['train'], y['train'])\n",
    "\n",
    "print(study_ce.best_params)\n",
    "print(study_ce.best_value)\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    accuracy = ComputeAccuracy(\n",
    "                                y_true=y[kind_of_data],\n",
    "                                y_pred=clf_ce.predict(X[kind_of_data])\n",
    "                            )\n",
    "    print('{}:\\t{}'.format(kind_of_data, accuracy))\n",
    "\"\"\"\n",
    "{'C': 41.12526644708382, 'solver': 'lbfgs'}\n",
    "0.22358193987305136\n",
    "train:\t0.9985944527736131\n",
    "valid:\t0.9160419790104948\n",
    "test:\t0.9152923538230885\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 147.85499072843322, 'solver': 'liblinear'}\n",
      "0.9205397301349325\n",
      "train:\t0.9995314842578711\n",
      "valid:\t0.9205397301349325\n",
      "test:\t0.9167916041979011\n"
     ]
    }
   ],
   "source": [
    "# 4.4 縦の線をまっすぐにする\n",
    "# 6.7 名前付き引数\n",
    "clf_acc = LogisticRegression(\n",
    "                                random_state=0,\n",
    "                                C=best_acc_params['C'],\n",
    "                                solver=best_acc_params['solver']\n",
    "                        ).fit(X['train'], y['train'])\n",
    "\n",
    "print(study_acc.best_params)\n",
    "print(study_acc.best_value)\n",
    "for kind_of_data in ['train', 'valid', 'test']:\n",
    "    accuracy = ComputeAccuracy(\n",
    "                                y_true=y[kind_of_data],\n",
    "                                y_pred=clf_acc.predict(X[kind_of_data])\n",
    "                            )\n",
    "    print('{}:\\t{}'.format(kind_of_data, accuracy))\n",
    "\"\"\"\n",
    "{'C': 147.85499072843322, 'solver': 'liblinear'}\n",
    "0.9205397301349325\n",
    "train:\t0.9995314842578711\n",
    "valid:\t0.9205397301349325\n",
    "test:\t0.9167916041979011\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlf0IPJdKbqg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKokGyy8/Nw36ltncwa9AV",
   "collapsed_sections": [],
   "mount_file_id": "12ob2YqGLRI4W1sUAznqYW_ITQnOU01V3",
   "name": "50-59.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
